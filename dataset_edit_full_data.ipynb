{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import torch\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from transformers import T5TokenizerFast, T5ForConditionalGeneration\n",
    "from tqdm.notebook import tqdm\n",
    "from collections import Counter\n",
    "from torch import nn\n",
    "from catalyst import dl\n",
    "from langdetect import detect\n",
    "\n",
    "DOCS_DIR = 'wiki_data_old/downloaded_data/documents_new'\n",
    "PAGES_DIR = 'wiki_data_old/downloaded_data/revision_new'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.10.1+cu102'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class Config:\n",
    "    pass\n",
    "    \n",
    "CONFIG = Config()\n",
    "CONFIG.seed = 1337\n",
    "CONFIG.src_max_len = 900\n",
    "CONFIG.tgt_max_len = 900\n",
    "CONFIG.pretrained = 't5-small'\n",
    "CONFIG.batch_size = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[8766, 3571, 7671, 3463, 6720]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_ids = list(map(lambda x: int(x.split('.')[0]), os.listdir(DOCS_DIR)))\n",
    "dataset_ids[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45f3523503354a86b6c5878235885202",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=11298.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "db_dict = {'obj_id': [], 'old_text': [], 'new_text': [], 'comment': [], 'docs': [], 'diff': []}\n",
    "for dataset_obj_id in tqdm(dataset_ids):\n",
    "    with open(f\"{PAGES_DIR}/{dataset_obj_id}.json\", 'r', encoding='utf-8') as f:\n",
    "        page_json = json.load(f)\n",
    "    docs_text = ''\n",
    "    added_docs = set()\n",
    "    count_docs = 0\n",
    "    with open(f\"{DOCS_DIR}/{dataset_obj_id}.txt\", 'r', encoding='utf-8') as f:\n",
    "        docs_text_plain = f.read()\n",
    "        docs = docs_text_plain.split('\\n\\nDOC_DELIMITER_TOKEN\\n\\n')\n",
    "        for doc_id, doc in enumerate(docs):\n",
    "            if doc not in added_docs:\n",
    "                added_docs.add(doc)\n",
    "                count_docs += 1\n",
    "                docs_text += f\" DOC{count_docs}: {doc}\"\n",
    "            if count_docs > 2:\n",
    "                break\n",
    "\n",
    "    if count_docs < 3:\n",
    "        continue\n",
    "    if 'link' in db_dict['comment'] or 'ref' in db_dict['comment']:\n",
    "        continue\n",
    "    try:\n",
    "        text_lang = detect(page_json['old_text'])\n",
    "        comment_lang = detect(page_json['comment'])\n",
    "    except:\n",
    "        text_lang = ''\n",
    "        comment_lang = ''\n",
    "\n",
    "    if text_lang == 'en':\n",
    "        diff = '\\n'.join(page_json['change_texts'][0][0])\n",
    "        db_dict['diff'].append(diff)\n",
    "        db_dict['obj_id'].append(dataset_obj_id)\n",
    "        db_dict['old_text'].append(page_json['old_text'])\n",
    "        db_dict['new_text'].append(page_json['new_text'])\n",
    "        db_dict['comment'].append('Comment: ' + page_json['comment'])\n",
    "        db_dict['docs'].append(docs_text.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8700, 6)\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame.from_dict(db_dict)\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "random.seed(CONFIG.seed)\n",
    "os.environ['PYTHONHASHSEED'] = str(CONFIG.seed)\n",
    "np.random.seed(CONFIG.seed)\n",
    "torch.manual_seed(CONFIG.seed)\n",
    "torch.cuda.manual_seed(CONFIG.seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_idxs = np.random.choice(df.shape[0], 103)\n",
    "all_idxs = np.arange(df.shape[0])\n",
    "other_idxs = np.setdiff1d(all_idxs, test_idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = df.iloc[test_idxs]\n",
    "df = df.iloc[other_idxs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>obj_id</th>\n",
       "      <th>old_text</th>\n",
       "      <th>new_text</th>\n",
       "      <th>comment</th>\n",
       "      <th>docs</th>\n",
       "      <th>diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8766</td>\n",
       "      <td>Andronicus of Cyrrhus was a Greek astronomer w...</td>\n",
       "      <td>Andronicus of Cyrrhus was a Greek astronomer w...</td>\n",
       "      <td>Comment: [[sl:Andronik]]</td>\n",
       "      <td>DOC1: Andronicus of Cyrrhus or Andronicus Cyrr...</td>\n",
       "      <td>\\n\\n\\n\\nsl:Andronik</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6720</td>\n",
       "      <td>*Much of the material in these articles comes ...</td>\n",
       "      <td>*Much of the material in these articles comes ...</td>\n",
       "      <td>Comment: =External links=</td>\n",
       "      <td>DOC1: Costa Rica (UK: / ˌ k ɒ s t ə ˈ r iː k ə...</td>\n",
       "      <td>\\nde:Costa Rica et:Costa Rica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1870</td>\n",
       "      <td>Christian Goldbach (1690 - 1764), was a Prussi...</td>\n",
       "      <td>Christian Goldbach (March 18,1690 - November 2...</td>\n",
       "      <td>Comment: Added dates of birth and death</td>\n",
       "      <td>DOC1: Christian Goldbach, (born March 18, 1690...</td>\n",
       "      <td>March 18,\\nNovember 20,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9051</td>\n",
       "      <td>* African Studies Association of the United Ki...</td>\n",
       "      <td>* African Studies Association of the United Ki...</td>\n",
       "      <td>Comment: /* Education */ added Alandica Shippi...</td>\n",
       "      <td>DOC1: Alandica Shipping Academy: Maritime educ...</td>\n",
       "      <td>Alandica Shipping Academy, Åland Islands, Finl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5712</td>\n",
       "      <td>* online and downloadable Bambara-French Dicti...</td>\n",
       "      <td>* online and downloadable Bambara-French Dicti...</td>\n",
       "      <td>Comment: /* Dictionaries */ Added an additiona...</td>\n",
       "      <td>DOC1: $20.87 5 New from $20.87 This book is in...</td>\n",
       "      <td>Mobile friendly Bambara-English dictionary. Ad...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   obj_id                                           old_text  \\\n",
       "0    8766  Andronicus of Cyrrhus was a Greek astronomer w...   \n",
       "1    6720  *Much of the material in these articles comes ...   \n",
       "2    1870  Christian Goldbach (1690 - 1764), was a Prussi...   \n",
       "3    9051  * African Studies Association of the United Ki...   \n",
       "4    5712  * online and downloadable Bambara-French Dicti...   \n",
       "\n",
       "                                            new_text  \\\n",
       "0  Andronicus of Cyrrhus was a Greek astronomer w...   \n",
       "1  *Much of the material in these articles comes ...   \n",
       "2  Christian Goldbach (March 18,1690 - November 2...   \n",
       "3  * African Studies Association of the United Ki...   \n",
       "4  * online and downloadable Bambara-French Dicti...   \n",
       "\n",
       "                                             comment  \\\n",
       "0                           Comment: [[sl:Andronik]]   \n",
       "1                          Comment: =External links=   \n",
       "2            Comment: Added dates of birth and death   \n",
       "3  Comment: /* Education */ added Alandica Shippi...   \n",
       "4  Comment: /* Dictionaries */ Added an additiona...   \n",
       "\n",
       "                                                docs  \\\n",
       "0  DOC1: Andronicus of Cyrrhus or Andronicus Cyrr...   \n",
       "1  DOC1: Costa Rica (UK: / ˌ k ɒ s t ə ˈ r iː k ə...   \n",
       "2  DOC1: Christian Goldbach, (born March 18, 1690...   \n",
       "3  DOC1: Alandica Shipping Academy: Maritime educ...   \n",
       "4  DOC1: $20.87 5 New from $20.87 This book is in...   \n",
       "\n",
       "                                                diff  \n",
       "0                                \\n\\n\\n\\nsl:Andronik  \n",
       "1                      \\nde:Costa Rica et:Costa Rica  \n",
       "2                            March 18,\\nNovember 20,  \n",
       "3  Alandica Shipping Academy, Åland Islands, Finl...  \n",
       "4  Mobile friendly Bambara-English dictionary. Ad...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tgt(row, text_to_lower=True, comment_to_lower=True, comment_delimiter=' TEXT '):\n",
    "    new_text = row.new_text.lower() if text_to_lower else row.new_text\n",
    "    coms = row.comment.lower() if comment_to_lower else row.comment\n",
    "    tgt = coms + comment_delimiter + new_text\n",
    "    return tgt\n",
    "\n",
    "def get_src(row, text_to_lower=True, comment_to_lower=True, doc_delimiter=' DOCS '):\n",
    "    old_text = row.old_text.lower() if text_to_lower else row.old_text \n",
    "    docs = row.docs.lower() if text_to_lower else row.docs \n",
    "    src = 'TEXT ' + old_text + doc_delimiter + docs\n",
    "    return src\n",
    "    \n",
    "class EditDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, dataset: list, tokenizer, config,\n",
    "                 text_to_lower=True, comment_to_lower=True):\n",
    "        self.db = dataset\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "        \n",
    "        src_text = self.db.apply(lambda x: get_src(x, text_to_lower, comment_to_lower), axis=1).values\n",
    "        tgt_text = self.db.apply(lambda x: get_tgt(x, text_to_lower, comment_to_lower), axis=1).values\n",
    "        \n",
    "        self.src_text_tokenized = [tokenizer(x,\n",
    "                                       max_length=config.src_max_len,\n",
    "                                       truncation=True,\n",
    "                                       return_attention_mask=False,\n",
    "                                       ) for x in src_text]\n",
    "        self.tgt_text_tokenized = [tokenizer(x,\n",
    "                                       max_length=config.tgt_max_len,\n",
    "                                       truncation=True,\n",
    "                                       return_attention_mask=False,\n",
    "                                       ) for x in tgt_text]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.db)\n",
    "\n",
    "    def __getitem__(self, idx: int):\n",
    "        src = self.src_text_tokenized[idx]\n",
    "        tgt = self.tgt_text_tokenized[idx]\n",
    "        return src, tgt\n",
    "\n",
    "    @staticmethod\n",
    "    def collate_fn(samples, tokenizer, config):\n",
    "        src_samples = [x[0] for x in samples]\n",
    "        tgt_samples = [x[1] for x in samples]\n",
    "\n",
    "        src_samples = tokenizer.pad(src_samples,\n",
    "                                    padding='longest',\n",
    "                                    max_length=config.final_src_max_len,\n",
    "                                    return_attention_mask=False,\n",
    "                                    return_tensors='pt')['input_ids']\n",
    "\n",
    "        tgt_samples = tokenizer.pad(tgt_samples,\n",
    "                                    padding='longest',\n",
    "                                    max_length=config.final_tgt_max_len,\n",
    "                                    return_attention_mask=False,\n",
    "                                    return_tensors='pt')['input_ids']\n",
    "\n",
    "        return (src_samples, tgt_samples), torch.ones(len(samples), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = T5TokenizerFast.from_pretrained(CONFIG.pretrained, model_max_length=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_edit = EditDataset(df, tokenizer, CONFIG, text_to_lower=True, comment_to_lower=True)\n",
    "ds_val = EditDataset(df_test, tokenizer, CONFIG, text_to_lower=True, comment_to_lower=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "arr_src = []\n",
    "arr_tgt = []\n",
    "for src_q, tgt_q in ds_edit:\n",
    "    arr_src.append(len(src_q['input_ids']))\n",
    "    arr_tgt.append(len(tgt_q['input_ids']))\n",
    "\n",
    "sns.distplot(arr_src, label='Src');\n",
    "plt.legend();\n",
    "sns.distplot(arr_tgt, label='Tgt');\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG.batch_size = 4\n",
    "CONFIG.final_src_max_len = 700\n",
    "CONFIG.final_tgt_max_len = 400\n",
    "loaders = {\n",
    "    'train': torch.utils.data.DataLoader(ds_edit, \n",
    "                                         batch_size=CONFIG.batch_size,\n",
    "                                         collate_fn=lambda x: EditDataset.collate_fn(x, tokenizer, CONFIG),\n",
    "                                         num_workers=4, shuffle=True),\n",
    "    'valid': torch.utils.data.DataLoader(ds_val, \n",
    "                                         batch_size=CONFIG.batch_size,\n",
    "                                         collate_fn=lambda x: EditDataset.collate_fn(x, tokenizer, CONFIG),\n",
    "                                         num_workers=4, shuffle=True)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EditModel(nn.Module):\n",
    "    def __init__(self, pretrained, config):\n",
    "        super(EditModel, self).__init__()\n",
    "        self.pretrained = pretrained\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        src, tgt = x\n",
    "        \n",
    "        tgt[tgt == 0] == -100\n",
    "        \n",
    "        loss = self.pretrained(\n",
    "            input_ids = src,\n",
    "            attention_mask = (src != 0).float(),\n",
    "            labels=tgt,\n",
    "        ).loss\n",
    "        return loss\n",
    "    \n",
    "    \n",
    "class Criterion(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Criterion, self).__init__()\n",
    "        \n",
    "    def forward(self, pred, tgt):\n",
    "        return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = EditModel(\n",
    "    T5ForConditionalGeneration.from_pretrained(CONFIG.pretrained),\n",
    "    CONFIG\n",
    ")\n",
    "CONFIG.optimizer = 'Adam(lr=0.0001)'\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
    "\n",
    "CONFIG.name = f'{CONFIG.pretrained}_test_8000objs'\n",
    "CONFIG.description = f'{CONFIG.name} p(comment, x_t+1 | x_t, doc)'\n",
    "CONFIG.group = \"wiki_edit_test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf ./models/\"{CONFIG.description}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import catalyst\n",
    "\n",
    "from catalyst.core import IRunner\n",
    "from catalyst.metrics._additive import AdditiveMetric\n",
    "from catalyst.callbacks.metric import BatchMetricCallback, ICallbackBatchMetric\n",
    "\n",
    "\n",
    "class ExactMatchMetric(ICallbackBatchMetric):\n",
    "    def __init__(self, topk, compute_on_call=False):\n",
    "        super().__init__(compute_on_call=compute_on_call, prefix='', suffix='')\n",
    "        self.metric_name = 'exact_match'\n",
    "        self.topk = topk\n",
    "        self.metrics: List[AdditiveMetric] = [\n",
    "            AdditiveMetric(compute_on_call=compute_on_call) for _ in range(len(self.topk))]\n",
    "\n",
    "    def reset(self) -> None:\n",
    "        for metric in self.metrics:\n",
    "            metric.reset()\n",
    "\n",
    "    def update(self, values, n_samples):\n",
    "        for value, metric in zip(values, self.metrics):\n",
    "            metric.update(value, n_samples)\n",
    "        return values\n",
    "\n",
    "    def update_key_value(self, values, n_samples):\n",
    "        values = self.update(values, n_samples)\n",
    "        output = {\n",
    "            f\"{self.prefix}{self.metric_name}{key:02d}{self.suffix}\": round(value, 6)\n",
    "            for key, value in zip(self.topk, values)\n",
    "        }\n",
    "        return output\n",
    "\n",
    "    def compute(self):\n",
    "        means, stds = zip(*(metric.compute() for metric in self.metrics))\n",
    "        return means, stds\n",
    "\n",
    "    def compute_key_value(self):\n",
    "        means, stds = self.compute()\n",
    "        output_mean = {\n",
    "            f\"{self.prefix}{self.metric_name}{key:02d}{self.suffix}\": round(value, 6)\n",
    "            for key, value in zip(self.topk, means)\n",
    "        }\n",
    "        output_std = {\n",
    "            f\"{self.prefix}{self.metric_name}{key:02d}{self.suffix}/std\": round(value, 6)\n",
    "            for key, value in zip(self.topk, stds)\n",
    "        }\n",
    "        return {**output_mean, **output_std}\n",
    "\n",
    "\n",
    "class ExactMatchCallback(BatchMetricCallback):\n",
    "\n",
    "    def __init__(self, beam_size):\n",
    "        super().__init__(\n",
    "            metric= ExactMatchMetric((1,beam_size)) if beam_size > 1 else ExactMatchMetric((1,)),\n",
    "            input_key='features', target_key='targets', log_on_batch=True)\n",
    "        self.beam_size = beam_size\n",
    "\n",
    "    def on_batch_end(self, runner: \"IRunner\") -> None:\n",
    "\n",
    "        if runner.loader_key == 'train':\n",
    "            runner.model.train()\n",
    "        elif runner.loader_key.startswith('valid'):\n",
    "            runner.model.eval()\n",
    "\n",
    "            src = runner.batch['features'][0]\n",
    "            tgt = runner.batch['features'][1]\n",
    "            max_len = tgt.shape[1]\n",
    "            with torch.no_grad():\n",
    "                pred = runner.model.pretrained.generate(src.to(runner.engine.device),\n",
    "                                                        attention_mask=(src != 0).float().to(runner.engine.device),\n",
    "                                                        # pad_token_id=tokenizer.pad_token_id,\n",
    "                                                        # bos_token_id=tokenizer.bos_token_id,\n",
    "                                                        # eos_token_id=tokenizer.eos_token_id,\n",
    "                                                        num_beams=self.beam_size,\n",
    "                                                        num_return_sequences=self.beam_size,\n",
    "                                                        max_length=max_len\n",
    "                                                        )\n",
    "\n",
    "            pred = pred[:,1:]\n",
    "            pred = pred.view(-1, self.beam_size, pred.shape[1])\n",
    "            acck = 0\n",
    "            acc1 = 0\n",
    "            for i in range(tgt.shape[0]):\n",
    "                tgt_subseq = tgt[i, :pred.shape[2]].to(runner.engine.device)\n",
    "\n",
    "                acck += float(torch.any(torch.all(tgt_subseq == pred[i], dim=1)))\n",
    "                acc1 += float(torch.all(tgt_subseq == pred[i, 0]))\n",
    "\n",
    "            acck /= len(src)\n",
    "            acc1 /= len(src)\n",
    "\n",
    "            metrics = self.metric.update_key_value([acc1, acck], len(src))\n",
    "\n",
    "            runner.batch_metrics.update(metrics)\n",
    "\n",
    "    def on_loader_end(self, runner: \"IRunner\") -> None:\n",
    "        if runner.loader_key.startswith('valid'):\n",
    "            metrics = self.metric.compute_key_value()\n",
    "            metrics = runner.engine.mean_reduce_ddp_metrics(metrics)\n",
    "            runner.loader_metrics.update(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG.n_epochs = 1000\n",
    "CONFIG.beam_size = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33manton-sh\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/ubuntu/interactive_lm/wiki/wandb/run-20221210_073432-2n0x0t7j</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/anton-sh/interactive_lm/runs/2n0x0t7j\" target=\"_blank\">t5-small_test_8000objs</a></strong> to <a href=\"https://wandb.ai/anton-sh/interactive_lm\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1def951cc4ef4e4da635c4a9a4f6094f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='1/1000 * Epoch (train)', max=2150.0, style=ProgressStyle(…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "train (1/1000) loss: 0.6272546833268442 | loss/mean: 0.6272546833268442 | loss/std: 0.38733012801269545 | lr: 0.0001 | momentum: 0.9\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "083aa6b4678b4792a2a5981018955e1f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='1/1000 * Epoch (valid)', max=26.0, style=ProgressStyle(de…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "valid (1/1000) exact_match01: 0.0 | exact_match01/std: 0.0 | exact_match05: 0.0 | exact_match05/std: 0.0 | loss: 0.45876882626460147 | loss/mean: 0.45876882626460147 | loss/std: 0.10400519678107419 | lr: 0.0001 | momentum: 0.9\n",
      "* Epoch (1/1000) \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d45b1a18f9a3431daa4dd2b2cd130728",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='2/1000 * Epoch (train)', max=2150.0, style=ProgressStyle(…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "train (2/1000) loss: 0.46719434735386883 | loss/mean: 0.46719434735386883 | loss/std: 0.15788139246286462 | lr: 0.0001 | momentum: 0.9\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9910e39f1c2474ebec4f3c804109902",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='2/1000 * Epoch (valid)', max=26.0, style=ProgressStyle(de…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "valid (2/1000) exact_match01: 0.0 | exact_match01/std: 0.0 | exact_match05: 0.0 | exact_match05/std: 0.0 | loss: 0.4350523020212467 | loss/mean: 0.4350523020212467 | loss/std: 0.11588442445587019 | lr: 0.0001 | momentum: 0.9\n",
      "* Epoch (2/1000) \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f42cf9700534e019348981c65d2bd0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='3/1000 * Epoch (train)', max=2150.0, style=ProgressStyle(…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "train (3/1000) loss: 0.4378365310645385 | loss/mean: 0.4378365310645385 | loss/std: 0.15060667953774268 | lr: 0.0001 | momentum: 0.9\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72d82a34e2f04b3e8b7c7f43285b10b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='3/1000 * Epoch (valid)', max=26.0, style=ProgressStyle(de…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "valid (3/1000) exact_match01: 0.0 | exact_match01/std: 0.0 | exact_match05: 0.0 | exact_match05/std: 0.0 | loss: 0.4280292454820413 | loss/mean: 0.4280292454820413 | loss/std: 0.1444781825078894 | lr: 0.0001 | momentum: 0.9\n",
      "* Epoch (3/1000) \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1775fae1b6a4444d94f37ada14f18235",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='4/1000 * Epoch (train)', max=2150.0, style=ProgressStyle(…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "train (4/1000) loss: 0.4171472633785985 | loss/mean: 0.4171472633785985 | loss/std: 0.15221851028384262 | lr: 0.0001 | momentum: 0.9\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12414ebc0a46419ba2c5910ad4abbe55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='4/1000 * Epoch (valid)', max=26.0, style=ProgressStyle(de…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "valid (4/1000) exact_match01: 0.0 | exact_match01/std: 0.0 | exact_match05: 0.0 | exact_match05/std: 0.0 | loss: 0.42538454268987363 | loss/mean: 0.42538454268987363 | loss/std: 0.12645906391816453 | lr: 0.0001 | momentum: 0.9\n",
      "* Epoch (4/1000) \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0b1da1212624afdb9f5b7480e42e147",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='5/1000 * Epoch (train)', max=2150.0, style=ProgressStyle(…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "train (5/1000) loss: 0.39919946717661486 | loss/mean: 0.39919946717661486 | loss/std: 0.14472825888604263 | lr: 0.0001 | momentum: 0.9\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57fa2304855842d5a1a6746bc946a7b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='5/1000 * Epoch (valid)', max=26.0, style=ProgressStyle(de…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "valid (5/1000) exact_match01: 0.0 | exact_match01/std: 0.0 | exact_match05: 0.0 | exact_match05/std: 0.0 | loss: 0.42659470037772107 | loss/mean: 0.42659470037772107 | loss/std: 0.1646660473372428 | lr: 0.0001 | momentum: 0.9\n",
      "* Epoch (5/1000) \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "afc8b6f729f94a419c7566b5cc89a0ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='6/1000 * Epoch (train)', max=2150.0, style=ProgressStyle(…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "train (6/1000) loss: 0.38506892451366614 | loss/mean: 0.38506892451366614 | loss/std: 0.14005534562842128 | lr: 0.0001 | momentum: 0.9\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "602303785f5a4bc5b606eb6777a16b1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='6/1000 * Epoch (valid)', max=26.0, style=ProgressStyle(de…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "valid (6/1000) exact_match01: 0.0 | exact_match01/std: 0.0 | exact_match05: 0.0 | exact_match05/std: 0.0 | loss: 0.413531034038617 | loss/mean: 0.413531034038617 | loss/std: 0.11081592031862374 | lr: 0.0001 | momentum: 0.9\n",
      "* Epoch (6/1000) \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a32f43c5e51b48d4b0f43fcb862fce3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='7/1000 * Epoch (train)', max=2150.0, style=ProgressStyle(…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "train (7/1000) loss: 0.3726201973197069 | loss/mean: 0.3726201973197069 | loss/std: 0.13596275799967403 | lr: 0.0001 | momentum: 0.9\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b351a54677bd40b6b4c78e49b9bc083b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='7/1000 * Epoch (valid)', max=26.0, style=ProgressStyle(de…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "valid (7/1000) exact_match01: 0.0 | exact_match01/std: 0.0 | exact_match05: 0.0 | exact_match05/std: 0.0 | loss: 0.4068947262488879 | loss/mean: 0.4068947262488879 | loss/std: 0.13639690595502288 | lr: 0.0001 | momentum: 0.9\n",
      "* Epoch (7/1000) \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd2c87a8d0c94a77b3123df55af8209f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='8/1000 * Epoch (train)', max=2150.0, style=ProgressStyle(…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "train (8/1000) loss: 0.3616074130666812 | loss/mean: 0.3616074130666812 | loss/std: 0.13209566498170908 | lr: 0.0001 | momentum: 0.9\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "619dfeba49dd476aac33bedccbd53ccb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='8/1000 * Epoch (valid)', max=26.0, style=ProgressStyle(de…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "valid (8/1000) exact_match01: 0.0 | exact_match01/std: 0.0 | exact_match05: 0.0 | exact_match05/std: 0.0 | loss: 0.4183182171904124 | loss/mean: 0.4183182171904124 | loss/std: 0.1495660568938825 | lr: 0.0001 | momentum: 0.9\n",
      "* Epoch (8/1000) \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9d31a6cad404f9d8e4ac4b45aa18aec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='9/1000 * Epoch (train)', max=2150.0, style=ProgressStyle(…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "train (9/1000) loss: 0.3518741815554536 | loss/mean: 0.3518741815554536 | loss/std: 0.1311502284913805 | lr: 0.0001 | momentum: 0.9\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5fcab6e6fa0f4370906058eafc3b1edf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='9/1000 * Epoch (valid)', max=26.0, style=ProgressStyle(de…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "valid (9/1000) exact_match01: 0.0 | exact_match01/std: 0.0 | exact_match05: 0.0 | exact_match05/std: 0.0 | loss: 0.41275703219267035 | loss/mean: 0.41275703219267035 | loss/std: 0.11773305164587018 | lr: 0.0001 | momentum: 0.9\n",
      "* Epoch (9/1000) \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af7a761779644ebc900db083af70a6f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='10/1000 * Epoch (train)', max=2150.0, style=ProgressStyle…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "train (10/1000) loss: 0.3431803250797965 | loss/mean: 0.3431803250797965 | loss/std: 0.12655585320539817 | lr: 0.0001 | momentum: 0.9\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b23ca09c9f8413e98a4d6ee43cafac7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='10/1000 * Epoch (valid)', max=26.0, style=ProgressStyle(d…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "valid (10/1000) exact_match01: 0.0 | exact_match01/std: 0.0 | exact_match05: 0.009709 | exact_match05/std: 0.048537 | loss: 0.4194608737642948 | loss/mean: 0.4194608737642948 | loss/std: 0.14100273306175623 | lr: 0.0001 | momentum: 0.9\n",
      "* Epoch (10/1000) \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7521dc0115a4e7d8a70990f37443a48",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='11/1000 * Epoch (train)', max=2150.0, style=ProgressStyle…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "train (11/1000) loss: 0.33544077492384083 | loss/mean: 0.33544077492384083 | loss/std: 0.12525374083316712 | lr: 0.0001 | momentum: 0.9\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14f354b3e031411eb9083e6678503644",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='11/1000 * Epoch (valid)', max=26.0, style=ProgressStyle(d…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "valid (11/1000) exact_match01: 0.0 | exact_match01/std: 0.0 | exact_match05: 0.009709 | exact_match05/std: 0.048537 | loss: 0.4159769129294616 | loss/mean: 0.4159769129294616 | loss/std: 0.14739950771707377 | lr: 0.0001 | momentum: 0.9\n",
      "* Epoch (11/1000) \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0aa1aed915f4b929f56784c3f2cd70c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='12/1000 * Epoch (train)', max=2150.0, style=ProgressStyle…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "train (12/1000) loss: 0.3248327711709708 | loss/mean: 0.3248327711709708 | loss/std: 0.11993831306854773 | lr: 0.0001 | momentum: 0.9\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd93768298bb4e75b3d8e113f5d04c19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='12/1000 * Epoch (valid)', max=26.0, style=ProgressStyle(d…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "valid (12/1000) exact_match01: 0.0 | exact_match01/std: 0.0 | exact_match05: 0.009709 | exact_match05/std: 0.048537 | loss: 0.41974436205167037 | loss/mean: 0.41974436205167037 | loss/std: 0.13286240605733382 | lr: 0.0001 | momentum: 0.9\n",
      "* Epoch (12/1000) \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd12f1d500264a72914405397851d33a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='13/1000 * Epoch (train)', max=2150.0, style=ProgressStyle…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "train (13/1000) loss: 0.31774214330454226 | loss/mean: 0.31774214330454226 | loss/std: 0.11878816792962377 | lr: 0.0001 | momentum: 0.9\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b36382738c5846398432292018cd72fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='13/1000 * Epoch (valid)', max=26.0, style=ProgressStyle(d…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "valid (13/1000) exact_match01: 0.0 | exact_match01/std: 0.0 | exact_match05: 0.009709 | exact_match05/std: 0.048537 | loss: 0.42678714486268854 | loss/mean: 0.42678714486268854 | loss/std: 0.11724428545127177 | lr: 0.0001 | momentum: 0.9\n",
      "* Epoch (13/1000) \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed192a58e7a946e7b2d9b14271a4742a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='14/1000 * Epoch (train)', max=2150.0, style=ProgressStyle…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "train (14/1000) loss: 0.3115923956140529 | loss/mean: 0.3115923956140529 | loss/std: 0.11984241831701287 | lr: 0.0001 | momentum: 0.9\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "789e6e4175d54b7c862cc2b75a5cc611",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='14/1000 * Epoch (valid)', max=26.0, style=ProgressStyle(d…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "valid (14/1000) exact_match01: 0.0 | exact_match01/std: 0.0 | exact_match05: 0.009709 | exact_match05/std: 0.048537 | loss: 0.43367407700190186 | loss/mean: 0.43367407700190186 | loss/std: 0.12868317199123255 | lr: 0.0001 | momentum: 0.9\n",
      "* Epoch (14/1000) \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cabeef94cf4b4efd9feff61329f20da8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='15/1000 * Epoch (train)', max=2150.0, style=ProgressStyle…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "train (15/1000) loss: 0.3048198278906738 | loss/mean: 0.3048198278906738 | loss/std: 0.11942565437754268 | lr: 0.0001 | momentum: 0.9\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7e6046f711d48028ae132e9e357d405",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='15/1000 * Epoch (valid)', max=26.0, style=ProgressStyle(d…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "valid (15/1000) exact_match01: 0.0 | exact_match01/std: 0.0 | exact_match05: 0.009709 | exact_match05/std: 0.048537 | loss: 0.4197951377584384 | loss/mean: 0.4197951377584384 | loss/std: 0.1429684158905377 | lr: 0.0001 | momentum: 0.9\n",
      "* Epoch (15/1000) \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea40c901e92541608d7ad8e1f673866b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='16/1000 * Epoch (train)', max=2150.0, style=ProgressStyle…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "train (16/1000) loss: 0.2966153215253079 | loss/mean: 0.2966153215253079 | loss/std: 0.11698555176003587 | lr: 0.0001 | momentum: 0.9\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2eca27ac8834b879c99e26556036429",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='16/1000 * Epoch (valid)', max=26.0, style=ProgressStyle(d…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "valid (16/1000) exact_match01: 0.0 | exact_match01/std: 0.0 | exact_match05: 0.009709 | exact_match05/std: 0.048537 | loss: 0.4314070395552194 | loss/mean: 0.4314070395552194 | loss/std: 0.15354346472418776 | lr: 0.0001 | momentum: 0.9\n",
      "* Epoch (16/1000) \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a714f1ffd40e4522999f150a2cabf31a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='17/1000 * Epoch (train)', max=2150.0, style=ProgressStyle…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "train (17/1000) loss: 0.2910037736438737 | loss/mean: 0.2910037736438737 | loss/std: 0.11036988410051042 | lr: 0.0001 | momentum: 0.9\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a03a9f6cf8fd4fa3b46ea22fde70a7fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='17/1000 * Epoch (valid)', max=26.0, style=ProgressStyle(d…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "valid (17/1000) exact_match01: 0.0 | exact_match01/std: 0.0 | exact_match05: 0.009709 | exact_match05/std: 0.048537 | loss: 0.43380710769158143 | loss/mean: 0.43380710769158143 | loss/std: 0.12799677771573045 | lr: 0.0001 | momentum: 0.9\n",
      "* Epoch (17/1000) \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40cfaabd70b04cafbe098a77f093e0d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='18/1000 * Epoch (train)', max=2150.0, style=ProgressStyle…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "train (18/1000) loss: 0.2846307042310409 | loss/mean: 0.2846307042310409 | loss/std: 0.11135421405473216 | lr: 0.0001 | momentum: 0.9\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27b7f5eaf7e8483cbd63ab3b8b05bb6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='18/1000 * Epoch (valid)', max=26.0, style=ProgressStyle(d…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "valid (18/1000) exact_match01: 0.0 | exact_match01/std: 0.0 | exact_match05: 0.009709 | exact_match05/std: 0.048537 | loss: 0.4378103166818619 | loss/mean: 0.4378103166818619 | loss/std: 0.13849040821808706 | lr: 0.0001 | momentum: 0.9\n",
      "* Epoch (18/1000) \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3108bf2f9f3f4932b55b3c35720ebc55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='19/1000 * Epoch (train)', max=2150.0, style=ProgressStyle…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "train (19/1000) loss: 0.27903399158009234 | loss/mean: 0.27903399158009234 | loss/std: 0.1063916014158719 | lr: 0.0001 | momentum: 0.9\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01a81c087ad641d9931fe9ee8396f35e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='19/1000 * Epoch (valid)', max=26.0, style=ProgressStyle(d…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "valid (19/1000) exact_match01: 0.009709 | exact_match01/std: 0.048537 | exact_match05: 0.009709 | exact_match05/std: 0.048537 | loss: 0.4292023462744859 | loss/mean: 0.4292023462744859 | loss/std: 0.1627992162286429 | lr: 0.0001 | momentum: 0.9\n",
      "* Epoch (19/1000) \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12ec6cdd082949929b2e58a986252871",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='20/1000 * Epoch (train)', max=2150.0, style=ProgressStyle…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "train (20/1000) loss: 0.27484805698658143 | loss/mean: 0.27484805698658143 | loss/std: 0.10473795227400917 | lr: 0.0001 | momentum: 0.9\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "656868d61cac46498391d7dd6df8cb1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='20/1000 * Epoch (valid)', max=26.0, style=ProgressStyle(d…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "valid (20/1000) exact_match01: 0.0 | exact_match01/std: 0.0 | exact_match05: 0.009709 | exact_match05/std: 0.048537 | loss: 0.44099737130678623 | loss/mean: 0.44099737130678623 | loss/std: 0.1361377315450881 | lr: 0.0001 | momentum: 0.9\n",
      "* Epoch (20/1000) \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f951d52fba7416e8716523118c9725e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='21/1000 * Epoch (train)', max=2150.0, style=ProgressStyle…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "train (21/1000) loss: 0.2682990560490035 | loss/mean: 0.2682990560490035 | loss/std: 0.10507179416333784 | lr: 0.0001 | momentum: 0.9\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2459a4d3ecf48c2be5a94248f6e12aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='21/1000 * Epoch (valid)', max=26.0, style=ProgressStyle(d…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "valid (21/1000) exact_match01: 0.009709 | exact_match01/std: 0.048537 | exact_match05: 0.009709 | exact_match05/std: 0.048537 | loss: 0.45020928635047036 | loss/mean: 0.45020928635047036 | loss/std: 0.1356256538541407 | lr: 0.0001 | momentum: 0.9\n",
      "* Epoch (21/1000) \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2971721a75fc469fa1398ebf23f9713d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='22/1000 * Epoch (train)', max=2150.0, style=ProgressStyle…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "train (22/1000) loss: 0.26128858959952095 | loss/mean: 0.26128858959952095 | loss/std: 0.10028967898399137 | lr: 0.0001 | momentum: 0.9\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1abc41d534e4cb9bfd004050ed2def1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='22/1000 * Epoch (valid)', max=26.0, style=ProgressStyle(d…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "valid (22/1000) exact_match01: 0.0 | exact_match01/std: 0.0 | exact_match05: 0.009709 | exact_match05/std: 0.048537 | loss: 0.45274004454796135 | loss/mean: 0.45274004454796135 | loss/std: 0.16365171630827302 | lr: 0.0001 | momentum: 0.9\n",
      "* Epoch (22/1000) \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f4cf54b5e5c4ab6a0195c199e453989",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='23/1000 * Epoch (train)', max=2150.0, style=ProgressStyle…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "train (23/1000) loss: 0.25798802636910345 | loss/mean: 0.25798802636910345 | loss/std: 0.10226714547835042 | lr: 0.0001 | momentum: 0.9\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c6580f0cb514fec840ca38a37d10ba9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='23/1000 * Epoch (valid)', max=26.0, style=ProgressStyle(d…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "valid (23/1000) exact_match01: 0.009709 | exact_match01/std: 0.048537 | exact_match05: 0.009709 | exact_match05/std: 0.048537 | loss: 0.43916509185846037 | loss/mean: 0.43916509185846037 | loss/std: 0.15744007700903043 | lr: 0.0001 | momentum: 0.9\n",
      "* Epoch (23/1000) \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2b43dd9fd684a61b4b6c658d2085be0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='24/1000 * Epoch (train)', max=2150.0, style=ProgressStyle…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "train (24/1000) loss: 0.25472586139343506 | loss/mean: 0.25472586139343506 | loss/std: 0.0986679635290502 | lr: 0.0001 | momentum: 0.9\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5b5a110e9024852b5052d9607b86a65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='24/1000 * Epoch (valid)', max=26.0, style=ProgressStyle(d…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "valid (24/1000) exact_match01: 0.009709 | exact_match01/std: 0.048537 | exact_match05: 0.009709 | exact_match05/std: 0.048537 | loss: 0.45134686392087214 | loss/mean: 0.45134686392087214 | loss/std: 0.16193890291620602 | lr: 0.0001 | momentum: 0.9\n",
      "* Epoch (24/1000) \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "321a612c3e0a45428f94bb9fe8f76abc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='25/1000 * Epoch (train)', max=2150.0, style=ProgressStyle…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "train (25/1000) loss: 0.24782688867387392 | loss/mean: 0.24782688867387392 | loss/std: 0.09733954475158599 | lr: 0.0001 | momentum: 0.9\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc9d3459bf634d97a0e3416b4f2709a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='25/1000 * Epoch (valid)', max=26.0, style=ProgressStyle(d…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "valid (25/1000) exact_match01: 0.009709 | exact_match01/std: 0.048537 | exact_match05: 0.009709 | exact_match05/std: 0.048537 | loss: 0.44155612244055825 | loss/mean: 0.44155612244055825 | loss/std: 0.14521676802230754 | lr: 0.0001 | momentum: 0.9\n",
      "* Epoch (25/1000) \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "693381a2a82f4d56a97103da308e35aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='26/1000 * Epoch (train)', max=2150.0, style=ProgressStyle…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "train (26/1000) loss: 0.24305079638264893 | loss/mean: 0.24305079638264893 | loss/std: 0.09437277077208221 | lr: 0.0001 | momentum: 0.9\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c96c2e1ee47243968ce879533ccb4c77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='26/1000 * Epoch (valid)', max=26.0, style=ProgressStyle(d…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "valid (26/1000) exact_match01: 0.009709 | exact_match01/std: 0.048537 | exact_match05: 0.009709 | exact_match05/std: 0.048537 | loss: 0.44662156127966374 | loss/mean: 0.44662156127966374 | loss/std: 0.1599067070090443 | lr: 0.0001 | momentum: 0.9\n",
      "* Epoch (26/1000) \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2363449637a41998b76298dd462ce5f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='27/1000 * Epoch (train)', max=2150.0, style=ProgressStyle…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "train (27/1000) loss: 0.23992703827141307 | loss/mean: 0.23992703827141307 | loss/std: 0.0950226229894536 | lr: 0.0001 | momentum: 0.9\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3fe607ad03fe4b88a8e7a62e92a6a6ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='27/1000 * Epoch (valid)', max=26.0, style=ProgressStyle(d…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "valid (27/1000) exact_match01: 0.009709 | exact_match01/std: 0.048537 | exact_match05: 0.009709 | exact_match05/std: 0.048537 | loss: 0.44918702657406145 | loss/mean: 0.44918702657406145 | loss/std: 0.1732885694102958 | lr: 0.0001 | momentum: 0.9\n",
      "* Epoch (27/1000) \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3acfd845732645b098424ea8b1151934",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='28/1000 * Epoch (train)', max=2150.0, style=ProgressStyle…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "train (28/1000) loss: 0.23613143570721115 | loss/mean: 0.23613143570721115 | loss/std: 0.09103940744251707 | lr: 0.0001 | momentum: 0.9\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "274c0bdb10f8448daa202a81496d2708",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='28/1000 * Epoch (valid)', max=26.0, style=ProgressStyle(d…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "valid (28/1000) exact_match01: 0.009709 | exact_match01/std: 0.056328 | exact_match05: 0.009709 | exact_match05/std: 0.056328 | loss: 0.4613822308870463 | loss/mean: 0.4613822308870463 | loss/std: 0.17776494986481325 | lr: 0.0001 | momentum: 0.9\n",
      "* Epoch (28/1000) \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c7174fce19c47818a4b9337a0296495",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='29/1000 * Epoch (train)', max=2150.0, style=ProgressStyle…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "train (29/1000) loss: 0.23114201090883382 | loss/mean: 0.23114201090883382 | loss/std: 0.09286329014214062 | lr: 0.0001 | momentum: 0.9\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7f53d04e4f940f6bbac621b4affad45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='29/1000 * Epoch (valid)', max=26.0, style=ProgressStyle(d…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "valid (29/1000) exact_match01: 0.009709 | exact_match01/std: 0.048537 | exact_match05: 0.009709 | exact_match05/std: 0.048537 | loss: 0.4641212884050148 | loss/mean: 0.4641212884050148 | loss/std: 0.17785651867135435 | lr: 0.0001 | momentum: 0.9\n",
      "* Epoch (29/1000) \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa651f3517434573a035f496832b8e8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='30/1000 * Epoch (train)', max=2150.0, style=ProgressStyle…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "train (30/1000) loss: 0.22618882875976143 | loss/mean: 0.22618882875976143 | loss/std: 0.08878420515670886 | lr: 0.0001 | momentum: 0.9\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae1b074344b349a5b42516774782872f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='30/1000 * Epoch (valid)', max=26.0, style=ProgressStyle(d…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "valid (30/1000) exact_match01: 0.009709 | exact_match01/std: 0.048537 | exact_match05: 0.009709 | exact_match05/std: 0.048537 | loss: 0.4671943485736847 | loss/mean: 0.4671943485736847 | loss/std: 0.133321284383794 | lr: 0.0001 | momentum: 0.9\n",
      "* Epoch (30/1000) \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6e0b3c39ef1469e9d2236a4438dfdd3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='31/1000 * Epoch (train)', max=2150.0, style=ProgressStyle…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "train (31/1000) loss: 0.22203826452237221 | loss/mean: 0.22203826452237221 | loss/std: 0.08710895726242626 | lr: 0.0001 | momentum: 0.9\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5776714eb4ae4e598a5d2d1a2f1555cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='31/1000 * Epoch (valid)', max=26.0, style=ProgressStyle(d…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "valid (31/1000) exact_match01: 0.009709 | exact_match01/std: 0.048537 | exact_match05: 0.009709 | exact_match05/std: 0.048537 | loss: 0.47153030679776126 | loss/mean: 0.47153030679776126 | loss/std: 0.15707022011583105 | lr: 0.0001 | momentum: 0.9\n",
      "* Epoch (31/1000) \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "071bed85af684da9887580c84e8e6840",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='32/1000 * Epoch (train)', max=2150.0, style=ProgressStyle…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "train (32/1000) loss: 0.21814328056088736 | loss/mean: 0.21814328056088736 | loss/std: 0.08744783618737234 | lr: 0.0001 | momentum: 0.9\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8aaef48f4e04148a864f0df50f88955",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='32/1000 * Epoch (valid)', max=26.0, style=ProgressStyle(d…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "valid (32/1000) exact_match01: 0.009709 | exact_match01/std: 0.048537 | exact_match05: 0.009709 | exact_match05/std: 0.048537 | loss: 0.4697353077622561 | loss/mean: 0.4697353077622561 | loss/std: 0.16514550361344785 | lr: 0.0001 | momentum: 0.9\n",
      "* Epoch (32/1000) \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9064ccc32e5442a0a57548aac5182089",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='33/1000 * Epoch (train)', max=2150.0, style=ProgressStyle…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "train (33/1000) loss: 0.2147219310285048 | loss/mean: 0.2147219310285048 | loss/std: 0.08368463924794818 | lr: 0.0001 | momentum: 0.9\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b094e560f5642109aa247cbe2676e53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='33/1000 * Epoch (valid)', max=26.0, style=ProgressStyle(d…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "valid (33/1000) exact_match01: 0.009709 | exact_match01/std: 0.056328 | exact_match05: 0.009709 | exact_match05/std: 0.056328 | loss: 0.4656140534923626 | loss/mean: 0.4656140534923626 | loss/std: 0.14662318822785556 | lr: 0.0001 | momentum: 0.9\n",
      "* Epoch (33/1000) \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2c907d5b48945c4a43d053ca040e45f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='34/1000 * Epoch (train)', max=2150.0, style=ProgressStyle…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "train (34/1000) loss: 0.21099620004552744 | loss/mean: 0.21099620004552744 | loss/std: 0.08256173825480508 | lr: 0.0001 | momentum: 0.9\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1933996735294a34bcd28adb5a2bf7b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='34/1000 * Epoch (valid)', max=26.0, style=ProgressStyle(d…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "valid (34/1000) exact_match01: 0.009709 | exact_match01/std: 0.048537 | exact_match05: 0.009709 | exact_match05/std: 0.048537 | loss: 0.4604885394756611 | loss/mean: 0.4604885394756611 | loss/std: 0.12030896347901633 | lr: 0.0001 | momentum: 0.9\n",
      "* Epoch (34/1000) \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1fab5ccc933f446abd44bd7fa2f173ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='35/1000 * Epoch (train)', max=2150.0, style=ProgressStyle…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "train (35/1000) loss: 0.20683687460110667 | loss/mean: 0.20683687460110667 | loss/std: 0.08166227257092237 | lr: 0.0001 | momentum: 0.9\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f8d64f8feda4b9f83c53973e9522b98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='35/1000 * Epoch (valid)', max=26.0, style=ProgressStyle(d…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "valid (35/1000) exact_match01: 0.009709 | exact_match01/std: 0.048537 | exact_match05: 0.009709 | exact_match05/std: 0.048537 | loss: 0.4794256389141083 | loss/mean: 0.4794256389141083 | loss/std: 0.1591921820164544 | lr: 0.0001 | momentum: 0.9\n",
      "* Epoch (35/1000) \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34c83aa79a39490b8d1dbfa15eb0142b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='36/1000 * Epoch (train)', max=2150.0, style=ProgressStyle…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "train (36/1000) loss: 0.20316726609891247 | loss/mean: 0.20316726609891247 | loss/std: 0.08038435655397906 | lr: 0.0001 | momentum: 0.9\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27df390fe49d4d5c816564c7cac82b14",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='36/1000 * Epoch (valid)', max=26.0, style=ProgressStyle(d…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "valid (36/1000) exact_match01: 0.009709 | exact_match01/std: 0.048537 | exact_match05: 0.009709 | exact_match05/std: 0.048537 | loss: 0.4901743450990089 | loss/mean: 0.4901743450990089 | loss/std: 0.17503068462047272 | lr: 0.0001 | momentum: 0.9\n",
      "* Epoch (36/1000) \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2525c60ff8f44fe8810e2735b9fc997",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='37/1000 * Epoch (train)', max=2150.0, style=ProgressStyle…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "train (37/1000) loss: 0.20092117817769234 | loss/mean: 0.20092117817769234 | loss/std: 0.08099733206492744 | lr: 0.0001 | momentum: 0.9\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5073cf801d4e4da28343933cc0ebd290",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='37/1000 * Epoch (valid)', max=26.0, style=ProgressStyle(d…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "valid (37/1000) exact_match01: 0.009709 | exact_match01/std: 0.048537 | exact_match05: 0.009709 | exact_match05/std: 0.048537 | loss: 0.4969413558451028 | loss/mean: 0.4969413558451028 | loss/std: 0.15271820213419332 | lr: 0.0001 | momentum: 0.9\n",
      "* Epoch (37/1000) \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63c923f8280c4227975c140c0daa9555",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='38/1000 * Epoch (train)', max=2150.0, style=ProgressStyle…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "train (38/1000) loss: 0.19560547121908783 | loss/mean: 0.19560547121908783 | loss/std: 0.07717779005029571 | lr: 0.0001 | momentum: 0.9\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1a09f499fcd45f08ac58cda4e56acc9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='38/1000 * Epoch (valid)', max=26.0, style=ProgressStyle(d…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "valid (38/1000) exact_match01: 0.009709 | exact_match01/std: 0.048537 | exact_match05: 0.009709 | exact_match05/std: 0.048537 | loss: 0.49390209695467585 | loss/mean: 0.49390209695467585 | loss/std: 0.18571020294792204 | lr: 0.0001 | momentum: 0.9\n",
      "* Epoch (38/1000) \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37ece628d7e8404eb76da0dcab977d83",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='39/1000 * Epoch (train)', max=2150.0, style=ProgressStyle…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "train (39/1000) loss: 0.1938266395430927 | loss/mean: 0.1938266395430927 | loss/std: 0.07575715658113981 | lr: 0.0001 | momentum: 0.9\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16d33fa9071a4304ae9fad7ac1a47c15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='39/1000 * Epoch (valid)', max=26.0, style=ProgressStyle(d…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "valid (39/1000) exact_match01: 0.009709 | exact_match01/std: 0.048537 | exact_match05: 0.009709 | exact_match05/std: 0.048537 | loss: 0.4918412067569219 | loss/mean: 0.4918412067569219 | loss/std: 0.16428149608416895 | lr: 0.0001 | momentum: 0.9\n",
      "* Epoch (39/1000) \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5bf94d2f7a240d2863545e9c6cb03e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='40/1000 * Epoch (train)', max=2150.0, style=ProgressStyle…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "train (40/1000) loss: 0.19065998138210094 | loss/mean: 0.19065998138210094 | loss/std: 0.07529229819006888 | lr: 0.0001 | momentum: 0.9\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eeda350f71b842418aec4edfa5c6f68c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='40/1000 * Epoch (valid)', max=26.0, style=ProgressStyle(d…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "valid (40/1000) exact_match01: 0.009709 | exact_match01/std: 0.048537 | exact_match05: 0.009709 | exact_match05/std: 0.048537 | loss: 0.4945808757956212 | loss/mean: 0.4945808757956212 | loss/std: 0.15372450364880416 | lr: 0.0001 | momentum: 0.9\n",
      "* Epoch (40/1000) \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6bfc9d9a2e854cd1b5e48d303d6ad4eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='41/1000 * Epoch (train)', max=2150.0, style=ProgressStyle…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "train (41/1000) loss: 0.18682336346181322 | loss/mean: 0.18682336346181322 | loss/std: 0.07376793712501395 | lr: 0.0001 | momentum: 0.9\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a26ec0d3aac435aa2c01eb3b318cd55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='41/1000 * Epoch (valid)', max=26.0, style=ProgressStyle(d…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "valid (41/1000) exact_match01: 0.009709 | exact_match01/std: 0.048537 | exact_match05: 0.009709 | exact_match05/std: 0.048537 | loss: 0.4977677114881001 | loss/mean: 0.4977677114881001 | loss/std: 0.17086663759111098 | lr: 0.0001 | momentum: 0.9\n",
      "* Epoch (41/1000) \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8339e9cedfc4006a44676458728e3c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='42/1000 * Epoch (train)', max=2150.0, style=ProgressStyle…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "train (42/1000) loss: 0.18411703341922073 | loss/mean: 0.18411703341922073 | loss/std: 0.07392568052638318 | lr: 0.0001 | momentum: 0.9\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68c776d622244d88a683bd13a7503071",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='42/1000 * Epoch (valid)', max=26.0, style=ProgressStyle(d…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "valid (42/1000) exact_match01: 0.009709 | exact_match01/std: 0.048537 | exact_match05: 0.009709 | exact_match05/std: 0.048537 | loss: 0.4929545802565722 | loss/mean: 0.4929545802565722 | loss/std: 0.17608258466378718 | lr: 0.0001 | momentum: 0.9\n",
      "* Epoch (42/1000) \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6881dd02c7d44140b691c5dcaea6b42f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='43/1000 * Epoch (train)', max=2150.0, style=ProgressStyle…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "train (43/1000) loss: 0.18065363323792502 | loss/mean: 0.18065363323792502 | loss/std: 0.07155997567675612 | lr: 0.0001 | momentum: 0.9\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43407b3c860b4d889f716ed013bc3cfb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='43/1000 * Epoch (valid)', max=26.0, style=ProgressStyle(d…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "valid (43/1000) exact_match01: 0.009709 | exact_match01/std: 0.048537 | exact_match05: 0.009709 | exact_match05/std: 0.048537 | loss: 0.5078935542931923 | loss/mean: 0.5078935542931923 | loss/std: 0.16930872385876167 | lr: 0.0001 | momentum: 0.9\n",
      "* Epoch (43/1000) \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93fcc15228514de98816289457501d71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='44/1000 * Epoch (train)', max=2150.0, style=ProgressStyle…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "train (44/1000) loss: 0.17795316698592728 | loss/mean: 0.17795316698592728 | loss/std: 0.07042466467658204 | lr: 0.0001 | momentum: 0.9\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "398c8dabb1ae4925886e93c98aa21b53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='44/1000 * Epoch (valid)', max=26.0, style=ProgressStyle(d…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "valid (44/1000) exact_match01: 0.009709 | exact_match01/std: 0.048537 | exact_match05: 0.009709 | exact_match05/std: 0.048537 | loss: 0.5171257154299663 | loss/mean: 0.5171257154299663 | loss/std: 0.16915918632380722 | lr: 0.0001 | momentum: 0.9\n",
      "* Epoch (44/1000) \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75c5f3596afa409185fa1b0d61ab7378",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='45/1000 * Epoch (train)', max=2150.0, style=ProgressStyle…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "train (45/1000) loss: 0.17430071495473373 | loss/mean: 0.17430071495473373 | loss/std: 0.07024448555837426 | lr: 0.0001 | momentum: 0.9\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9718e1b38b44a4c918a35af0737dfb3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='45/1000 * Epoch (valid)', max=26.0, style=ProgressStyle(d…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "valid (45/1000) exact_match01: 0.009709 | exact_match01/std: 0.048537 | exact_match05: 0.009709 | exact_match05/std: 0.048537 | loss: 0.5053676917002752 | loss/mean: 0.5053676917002752 | loss/std: 0.18598618610050882 | lr: 0.0001 | momentum: 0.9\n",
      "* Epoch (45/1000) \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa893267aa764e80b5e3544fcc450fed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='46/1000 * Epoch (train)', max=2150.0, style=ProgressStyle…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "train (46/1000) loss: 0.17140133480519734 | loss/mean: 0.17140133480519734 | loss/std: 0.06723268347073574 | lr: 0.0001 | momentum: 0.9\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec8c54c5f2f943aa809f1251a7e8c049",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='46/1000 * Epoch (valid)', max=26.0, style=ProgressStyle(d…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "valid (46/1000) exact_match01: 0.009709 | exact_match01/std: 0.048537 | exact_match05: 0.009709 | exact_match05/std: 0.048537 | loss: 0.5341316776779983 | loss/mean: 0.5341316776779983 | loss/std: 0.19939755816672503 | lr: 0.0001 | momentum: 0.9\n",
      "* Epoch (46/1000) \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c41d34899d47487dbc49b2c689a1cdd9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='47/1000 * Epoch (train)', max=2150.0, style=ProgressStyle…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "train (47/1000) loss: 0.1680593038852824 | loss/mean: 0.1680593038852824 | loss/std: 0.06709320290296952 | lr: 0.0001 | momentum: 0.9\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60512ba6eb6d4be18de6dfbeba1af85b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='47/1000 * Epoch (valid)', max=26.0, style=ProgressStyle(d…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "valid (47/1000) exact_match01: 0.009709 | exact_match01/std: 0.048537 | exact_match05: 0.009709 | exact_match05/std: 0.048537 | loss: 0.5074080629990652 | loss/mean: 0.5074080629990652 | loss/std: 0.17222200547085195 | lr: 0.0001 | momentum: 0.9\n",
      "* Epoch (47/1000) \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a20734e64934cb0a75b1bf3f73d5e8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='48/1000 * Epoch (train)', max=2150.0, style=ProgressStyle…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "train (48/1000) loss: 0.16660511975024986 | loss/mean: 0.16660511975024986 | loss/std: 0.06480882279638263 | lr: 0.0001 | momentum: 0.9\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94305a8386ed43459db09abb7f6deb3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='48/1000 * Epoch (valid)', max=26.0, style=ProgressStyle(d…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "valid (48/1000) exact_match01: 0.009709 | exact_match01/std: 0.048537 | exact_match05: 0.009709 | exact_match05/std: 0.048537 | loss: 0.5321246528854737 | loss/mean: 0.5321246528854737 | loss/std: 0.17756137658390297 | lr: 0.0001 | momentum: 0.9\n",
      "* Epoch (48/1000) \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b77c4e90d7c04fb9b7344d06dc49fa61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='49/1000 * Epoch (train)', max=2150.0, style=ProgressStyle…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "train (49/1000) loss: 0.16285168381277879 | loss/mean: 0.16285168381277879 | loss/std: 0.06510879866242424 | lr: 0.0001 | momentum: 0.9\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a278cd2140ea453aa5a6ed51035e80d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='49/1000 * Epoch (valid)', max=26.0, style=ProgressStyle(d…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "valid (49/1000) exact_match01: 0.009709 | exact_match01/std: 0.048537 | exact_match05: 0.009709 | exact_match05/std: 0.048537 | loss: 0.5215727950517949 | loss/mean: 0.5215727950517949 | loss/std: 0.22357615903392009 | lr: 0.0001 | momentum: 0.9\n",
      "* Epoch (49/1000) \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f14d34dd62c84401a3b4e244c0cd4fd1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='50/1000 * Epoch (train)', max=2150.0, style=ProgressStyle…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "train (50/1000) loss: 0.1599937985040417 | loss/mean: 0.1599937985040417 | loss/std: 0.062244521597447554 | lr: 0.0001 | momentum: 0.9\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2e974c9c4dc4eb1822f183db896aa3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='50/1000 * Epoch (valid)', max=26.0, style=ProgressStyle(d…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "valid (50/1000) exact_match01: 0.009709 | exact_match01/std: 0.048537 | exact_match05: 0.009709 | exact_match05/std: 0.048537 | loss: 0.536930582844294 | loss/mean: 0.536930582844294 | loss/std: 0.16256991690036726 | lr: 0.0001 | momentum: 0.9\n",
      "* Epoch (50/1000) \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45c83af60e504f608848ef11b7620b9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='51/1000 * Epoch (train)', max=2150.0, style=ProgressStyle…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "train (51/1000) loss: 0.15741815848752524 | loss/mean: 0.15741815848752524 | loss/std: 0.06204382862326527 | lr: 0.0001 | momentum: 0.9\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5cd49353baf94890928aa017d6a23483",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='51/1000 * Epoch (valid)', max=26.0, style=ProgressStyle(d…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "valid (51/1000) exact_match01: 0.009709 | exact_match01/std: 0.048537 | exact_match05: 0.009709 | exact_match05/std: 0.048537 | loss: 0.5165984728015387 | loss/mean: 0.5165984728015387 | loss/std: 0.1681429809560483 | lr: 0.0001 | momentum: 0.9\n",
      "* Epoch (51/1000) \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a506e8eed114d01b732b253cf05b6a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='52/1000 * Epoch (train)', max=2150.0, style=ProgressStyle…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "train (52/1000) loss: 0.1541181870723184 | loss/mean: 0.1541181870723184 | loss/std: 0.060375461809522406 | lr: 0.0001 | momentum: 0.9\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6dd6d7c22ce64320950126aa71eb5b21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='52/1000 * Epoch (valid)', max=26.0, style=ProgressStyle(d…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "valid (52/1000) exact_match01: 0.009709 | exact_match01/std: 0.048537 | exact_match05: 0.009709 | exact_match05/std: 0.048537 | loss: 0.5342437321176896 | loss/mean: 0.5342437321176896 | loss/std: 0.19655379790110075 | lr: 0.0001 | momentum: 0.9\n",
      "* Epoch (52/1000) \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "baef4082688e4b5998294d04a8192a94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='53/1000 * Epoch (train)', max=2150.0, style=ProgressStyle…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    }
   ],
   "source": [
    "runner = dl.SupervisedRunner()\n",
    "\n",
    "# CONFIG.scheduler = 'OneCycleLR(max_lr=0.005, base_momentum=0.85, max_momentum=0.95, div_factor=10.0)'\n",
    "\n",
    "wandb_logger = dl.WandbLogger(project=\"interactive_lm\", \n",
    "                              name=CONFIG.name, \n",
    "                              group=CONFIG.group)\n",
    "# wandb_logger.log_hparams(CONFIG.__dict__)\n",
    "\n",
    "runner.train(\n",
    "    loaders=loaders,\n",
    "    model=model,\n",
    "    criterion=Criterion(),\n",
    "    optimizer=optimizer,\n",
    "#     scheduler=torch.optim.lr_scheduler.OneCycleLR(optimizer, 0.005, \n",
    "#                                                   total_steps=CONFIG.n_epochs*len(loaders_pattern['train']), \n",
    "#                                                   base_momentum=0.85, max_momentum=0.95, div_factor=10.0),\n",
    "    num_epochs=CONFIG.n_epochs,\n",
    "    callbacks=[\n",
    "        # dl.EarlyStoppingCallback(loader_key='valid', metric_key='exact_match02', minimize=False, patience=5),\n",
    "        ExactMatchCallback(beam_size=CONFIG.beam_size),\n",
    "    ],\n",
    "    loggers={'wandb': wandb_logger},\n",
    "    logdir=f'./models/{CONFIG.description}',\n",
    "    valid_loader='valid',\n",
    "    valid_metric='loss',\n",
    "    minimize_valid_metric=True,\n",
    "    verbose=True,\n",
    "#     check=True,\n",
    "#     cpu=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "----------------------------\t QUERY 0\t ----------------------------\n",
      "\n",
      "Src query:\n",
      " TEXT andronicus of cyrrhus was a greek astronomer who flourished about 100 bc. he built a horologium at athens, the so-called tower of the winds, a considerable portion of which still exists. it is octagonal, with figures carved on each side, representing the eight principal winds. in antiquity a bronze figure of triton on the summit, with a rod in his hand, turned round by the wind, pointed to the quarter from which it blew. from this model is derived the custom of placing weathercocks on steeples. DOCS doc1: andronicus of cyrrhus or andronicus cyrrhestes ( greek: , andrónikos kyrrhstou ), son of hermias, was a greek astronomer best known as the architect of the horologion at athens called the tower of the winds. [1] andronicus also built a multifaced sundial in the sanctuary of poseidon on the greek island of tinos. doc2: andronicus of cyrrhus, also called andronicus cyrrhestes, (flourished c. 100 bce ), greek astronomer best known as the architect of the horologium at athens called the tower of the winds. andronicus also built a multifaced sundial in the sanctuary of poseidon on the greek island of tenos. doc3: andronicus of cyrrhus or andronicus cyrrhestes (greek: , andrónikos kyrrhstou), son of hermias, was a greek astronomer best known as the architect of the horologion at athens called the tower of the winds. read more on wikipedia\n",
      "\n",
      "Tgt query:\n",
      " comment: [[sl:andronik]] TEXT andronicus of cyrrhus was a greek astronomer who flourished about 100 bc. he built a horologium at athens, the so-called tower of the winds, a considerable portion of which still exists. it is octagonal, with figures carved on each side, representing the eight principal winds. in antiquity a bronze figure of triton on the summit, with a rod in his hand, turned round by the wind, pointed to the quarter from which it blew. from this model is derived the custom of placing weathercocks on steeples. sl:andronik\n",
      "\n",
      "\n",
      "----------------------------\t GENERATED\t ----------------------------\n",
      "\n",
      "0:\n",
      "comment: /* top */ cyrrhestes TEXT andronicus of cyrrhus was a greek astronomer who flourished about 100 bc. he built a horologium at athens, the so-called tower of the winds, a considerable portion of which still exists. it is octagonal, with figures carved on each side, representing the eight principal winds. in antiquity a bronze figure of triton on the summit, with a rod in his hand, turned round by the wind, pointed to the quarter from which it blew. from this model is derived the custom of placing weathercocks on steeples.\n",
      "\n",
      "1:\n",
      "comment: /* life */ cyrrhestes TEXT andronicus of cyrrhus was a greek astronomer who flourished about 100 bc. he built a horologium at athens, the so-called tower of the winds, a considerable portion of which still exists. it is octagonal, with figures carved on each side, representing the eight principal winds. in antiquity a bronze figure of triton on the summit, with a rod in his hand, turned round by the wind, pointed to the quarter from which it blew. from this model is derived the custom of placing weathercocks on steeples.\n",
      "\n",
      "2:\n",
      "comment: /* andronicus */ cyrrhestes TEXT andronicus of cyrrhus was a greek astronomer who flourished about 100 bc. he built a horologium at athens, the so-called tower of the winds, a considerable portion of which still exists. it is octagonal, with figures carved on each side, representing the eight principal winds. in antiquity a bronze figure of triton on the summit, with a rod in his hand, turned round by the wind, pointed to the quarter from which it blew. from this model is derived the custom of placing weathercocks on steeples.\n",
      "\n",
      "3:\n",
      "comment: /* top */ cyrrhestes TEXT andronicus of cyrrhus was a greek astronomer who flourished about 100 bc. he built a horologium at athens, the so-called tower of the winds, a considerable portion of which still exists. it is octagonal, with figures carved on each side, representing the eight principal winds. in antiquity a bronze figure of triton on the summit, with a rod in his hand, turned round by the wind, pointed to the quarter from which it blew. from this model is derived the custom of placing weather cocks on steeples.\n",
      "\n",
      "4:\n",
      "comment: /* top */ cyrrhestes TEXT andronicus of cyrrhus was a greek astronomer who flourished about 100 bc. he built a horologium at athens, the so-called tower of the winds, a considerable portion of which still exists. it is octagonal, with figures carved on each side, representing the eight principal winds. in antiquity a bronze figure of triton on the summit, with a rod in his hand, turned round by the wind, pointed to the quarter from which it blew. from this model is derived the custom of placing weathercocks on steeples., andronicus of cyrrhus * andronicus of cyrrhestes\n",
      "\n",
      "\n",
      "X_T:\n",
      "Andronicus of Cyrrhus was a Greek astronomer who flourished about 100 BC.\n",
      "\n",
      "He built a horologium at Athens, the so-called Tower of the Winds, a considerable portion of which still exists. It is octagonal, with figures carved on each side, representing the eight principal winds. In antiquity a bronze figure of Triton on the summit, with a rod in his hand, turned round by the wind, pointed to the quarter from which it blew. From this model is derived the custom of placing weathercocks on steeples.\n",
      "\n",
      "X_T+1:\n",
      "Andronicus of Cyrrhus was a Greek astronomer who flourished about 100 BC.\n",
      "\n",
      "He built a horologium at Athens, the so-called Tower of the Winds, a considerable portion of which still exists. It is octagonal, with figures carved on each side, representing the eight principal winds. In antiquity a bronze figure of Triton on the summit, with a rod in his hand, turned round by the wind, pointed to the quarter from which it blew. From this model is derived the custom of placing weathercocks on steeples.\n",
      "\n",
      "\n",
      "\n",
      "sl:Andronik\n",
      "\n",
      "diff:\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "sl:Andronik\n",
      "\n",
      "\n",
      "----------------------------\t QUERY 1\t ----------------------------\n",
      "\n",
      "Src query:\n",
      " TEXT *much of the material in these articles comes from the cia world factbook 2000 and the 2003 u.s. department of state website., international rankings world-wide press freedom index rank 15 out of 139 countries (2 way tie) * bbc country profile: costa rica de:costa rica et:costa rica eo:kostariko es:costa rica fr:costa rica it:costa rica ja: nl:costa rica pl:kostaryka ru:коста-рика sl:kostarika sv:costa rica DOCS doc1: costa rica (uk: /  k  s t   r i k  /, us: /  k o s t  / (); spanish: [kosta rika]; literally rich coast), officially the republic of costa rica (spanish: repblica de costa rica), is a country in the central american region of north america, bordered by nicaragua to the north, the caribbean sea to the northeast, panama to the southeast, the pacific ocean to the... doc2: costa rica is a country located in central america that is ranked as one of the most visited international destinations. one of costa ricas main sources of income is tourism. costa rica is a democratic and peaceful country and it has not had an army since the year 1948. doc3: costa rica references banks, j. r., crook, m. j., ennos, a. r. (1997). the function of buttress roots: a compartive study of the anchorage systems of buttressed and non-buttressed tropical trees. journal of experimental botany, 48 (314), 1703-1716. bussing, w. a. (1998). freshwater fishes of costa rica. editorial universidad de costa rica.\n",
      "\n",
      "Tgt query:\n",
      " comment: =external links= TEXT *much of the material in these articles comes from the cia world factbook 2000 and the 2003 u.s. department of state website., international rankings world-wide press freedom index rank 15 out of 139 countries (2 way tie) * bbc country profile: costa rica de:costa rica et:costa rica eo:kostariko es:costa rica fr:costa rica it:costa rica ja: nl:costa rica pl:kostaryka ru:коста-рика sl:kostarika sv:costa rica\n",
      "\n",
      "\n",
      "----------------------------\t GENERATED\t ----------------------------\n",
      "\n",
      "0:\n",
      "comment: [[category:costa rica]] TEXT *much of the material in these articles comes from the cia world factbook 2000 and the 2003 u.s. department of state website., international rankings world-wide press freedom index rank 15 out of 139 countries (2 way tie) * bbc country profile: costa rica de:costa rica et:costa rica eo:kostariko es:costa rica fr:costa rica it:costa rica ja: nl:costa rica pl:kostaryka ru:коста-рика sl:kostarika sv:costa rica\n",
      "\n",
      "1:\n",
      "comment: [[es:costa rica]] TEXT *much of the material in these articles comes from the cia world factbook 2000 and the 2003 u.s. department of state website., international rankings world-wide press freedom index rank 15 out of 139 countries (2 way tie) * bbc country profile: costa rica de:costa rica et:costa rica eo:kostariko es:costa rica fr:costa rica it:costa rica ja: nl:costa rica pl:kostaryka ru:коста-рика sl:kostarika sv:costa rica es:costa rica\n",
      "\n",
      "2:\n",
      "comment: interwiki TEXT *much of the material in these articles comes from the cia world factbook 2000 and the 2003 u.s. department of state website., international rankings world-wide press freedom index rank 15 out of 139 countries (2 way tie) * bbc country profile: costa rica de:costa rica et:costa rica eo:kostariko es:costa rica fr:costa rica it:costa rica ja: nl:costa rica pl:kostaryka ru:коста-рика sl:kostarika sv:costa rica nl:costa rica\n",
      "\n",
      "3:\n",
      "comment: [[es:costa rica]] TEXT *much of the material in these articles comes from the cia world factbook 2000 and the 2003 u.s. department of state website., international rankings world-wide press freedom index rank 15 out of 139 countries (2 way tie) * bbc country profile: costa rica de:costa rica et:costa rica eo:kostariko es:costa rica fr:costa rica it:costa rica es:costa rica ja: nl:costa rica pl:kostaryka ru:коста-рика sl:kostarika sv:costa rica es:costa rica\n",
      "\n",
      "4:\n",
      "comment: [[es:costa rica]] TEXT *much of the material in these articles comes from the cia world factbook 2000 and the 2003 u.s. department of state website., international rankings world-wide press freedom index rank 15 out of 139 countries (2 way tie) * bbc country profile: costa rica de:costa rica et:costa rica eo:kostariko es:costa rica fr:costa rica it:costa rica ja: nl:costa rica pl:kostaryka ru:коста-рика sl:kostarika sv:costa rica es:costa rica es:costa rica\n",
      "\n",
      "\n",
      "X_T:\n",
      "*Much of the material in these articles comes from the CIA World Factbook 2000 and the 2003 U.S. Department of State website.\n",
      "\n",
      ",   International rankings  world-wide press freedom index Rank 15 out of 139 countries (2 way tie)\n",
      "* BBC Country profile: Costa Rica\n",
      "\n",
      "de:Costa Rica et:Costa Rica eo:Kostariko es:Costa Rica fr:Costa Rica\n",
      "it:Costa Rica\n",
      "ja:コスタリカ nl:Costa Rica pl:Kostaryka ru:Коста-Рика sl:Kostarika sv:Costa Rica\n",
      "\n",
      "X_T+1:\n",
      "*Much of the material in these articles comes from the CIA World Factbook 2000 and the 2003 U.S. Department of State website.\n",
      "\n",
      ",   International rankings  world-wide press freedom index Rank 15 out of 139 countries (2 way tie)\n",
      "* BBC Country profile: Costa Rica\n",
      "\n",
      "\n",
      "de:Costa Rica et:Costa Rica eo:Kostariko es:Costa Rica fr:Costa Rica\n",
      "it:Costa Rica\n",
      "ja:コスタリカ nl:Costa Rica pl:Kostaryka ru:Коста-Рика sl:Kostarika sv:Costa Rica\n",
      "\n",
      "diff:\n",
      "\n",
      "de:Costa Rica et:Costa Rica\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "----------------------------\t QUERY 2\t ----------------------------\n",
      "\n",
      "Src query:\n",
      " TEXT christian goldbach (1690 - 1764), was a prussian mathematician, who was born in koenigsberg, prussia as son of a pastor. goldbach studied jura and mathematics. he traveled widely throughout europe and met with many famous mathematicians, such as leibniz, leonhard euler, nicolas i, bernoulli.goldbach went to work at the newly opened st.petersburg academy and became tutor to the later tsar peter ii. goldbach did important work in the mathematical field. he is remembered today for goldbach's conjecture. DOCS doc1: christian goldbach, (born march 18, 1690, königsberg, prussia [now kaliningrad, russia]—died nov. 20, 1764, moscow, russia), russian mathematician whose contributions to number theory include goldbachs conjecture. in 1725 goldbach became professor of mathematics and historian of the imperial academy at st. petersburg. doc2: christian goldbach (/   o l d b  k /; german: [ltbax]; 18 march 1690 - 20 november 1764) was a german mathematician connected with some important research mainly in number theory; he also studied law and took an interest in and a role in the russian court. after traveling around europe in his early life, he landed in russia in 1725 as a professor at the newly founded saint... doc3: christian goldbach was born on march 18, 1690, in königsberg, brandenburg-prussia (today kaliningrad, russian federation). he was the son of a pastor. education goldbach studied medicine and mathematics at the university of königsberg (today immanuel kant baltic federal university).\n",
      "\n",
      "Tgt query:\n",
      " comment: added dates of birth and death TEXT christian goldbach (march 18,1690 - november 20,1764), was a prussian mathematician, who was born in koenigsberg, prussia as son of a pastor. goldbach studied jura and mathematics. he traveled widely throughout europe and met with many famous mathematicians, such as leibniz, leonhard euler, nicolas i, bernoulli.goldbach went to work at the newly opened st.petersburg academy and became tutor to the later tsar peter ii. goldbach did important work in the mathematical field. he is remembered today for goldbach's conjecture.\n",
      "\n",
      "\n",
      "----------------------------\t GENERATED\t ----------------------------\n",
      "\n",
      "0:\n",
      "comment: fix link TEXT christian goldbach (march 18,1690 - november 20,1764), was a prussian mathematician, who was born in koenigsberg, prussia as son of a pastor. goldbach studied jura and mathematics. he traveled widely throughout europe and met with many famous mathematicians, such as leibniz, leonhard euler, nicolas i, bernoulli.goldbach went to work at the newly opened st.petersburg academy and became tutor to the later tsar peter ii. goldbach did important work in the mathematical field. he is remembered today for goldbach's conjecture.\n",
      "\n",
      "1:\n",
      "comment: added dates of birth and death TEXT christian goldbach (march 18,1690 - november 20,1764), was a prussian mathematician, who was born in koenigsberg, prussia as son of a pastor. goldbach studied jura and mathematics. he traveled widely throughout europe and met with many famous mathematicians, such as leibniz, leonhard euler, nicolas i, bernoulli.goldbach went to work at the newly opened st.petersburg academy and became tutor to the later tsar peter ii. goldbach did important work in the mathematical field. he is remembered today for goldbach's conjecture.\n",
      "\n",
      "2:\n",
      "comment: fix link TEXT christian goldbach (1690 - 1764), was a prussian mathematician, who was born in koenigsberg, prussia as son of a pastor. goldbach studied jura and mathematics. he traveled widely throughout europe and met with many famous mathematicians, such as leibniz, leonhard euler, nicolas i, bernoulli.goldbach went to work at the newly opened st.petersburg academy and became tutor to the later tsar peter ii. goldbach did important work in the mathematical field. he is remembered today for goldbach's conjecture.\n",
      "\n",
      "3:\n",
      "comment: added a date of birth TEXT christian goldbach (march 18,1690 - november 20,1764), was a prussian mathematician, who was born in koenigsberg, prussia as son of a pastor. goldbach studied jura and mathematics. he traveled widely throughout europe and met with many famous mathematicians, such as leibniz, leonhard euler, nicolas i, bernoulli.goldbach went to work at the newly opened st.petersburg academy and became tutor to the later tsar peter ii. goldbach did important work in the mathematical field. he is remembered today for goldbach's conjecture.\n",
      "\n",
      "4:\n",
      "comment: added a name TEXT christian goldbach (march 18,1690 - november 20,1764), was a prussian mathematician, who was born in koenigsberg, prussia as son of a pastor. goldbach studied jura and mathematics. he traveled widely throughout europe and met with many famous mathematicians, such as leibniz, leonhard euler, nicolas i, bernoulli.goldbach went to work at the newly opened st.petersburg academy and became tutor to the later tsar peter ii. goldbach did important work in the mathematical field. he is remembered today for goldbach's conjecture.\n",
      "\n",
      "\n",
      "X_T:\n",
      "Christian Goldbach (1690 - 1764), was a Prussian mathematician, who was born in Koenigsberg, Prussia as son of a pastor. Goldbach studied jura and mathematics. He traveled widely throughout Europe and met with many famous mathematicians, such as Leibniz, Leonhard Euler, Nicolas I, Bernoulli.Goldbach went to work at the newly opened St.Petersburg Academy and became tutor to the later Tsar Peter II.\n",
      "\n",
      "Goldbach did important work in the mathematical field. He is remembered today for Goldbach's conjecture.\n",
      "\n",
      "X_T+1:\n",
      "Christian Goldbach (March 18,1690 - November 20,1764), was a Prussian mathematician, who was born in Koenigsberg, Prussia as son of a pastor. Goldbach studied jura and mathematics. He traveled widely throughout Europe and met with many famous mathematicians, such as Leibniz, Leonhard Euler, Nicolas I, Bernoulli.Goldbach went to work at the newly opened St.Petersburg Academy and became tutor to the later Tsar Peter II.\n",
      "\n",
      "Goldbach did important work in the mathematical field. He is remembered today for Goldbach's conjecture.\n",
      "\n",
      "diff:\n",
      "March 18,\n",
      "November 20,\n",
      "\n",
      "\n",
      "----------------------------\t QUERY 3\t ----------------------------\n",
      "\n",
      "Src query:\n",
      " TEXT * african studies association of the united kingdom * african studies association * albany students' association, at massey university, auckland, new zealand * alexander-smith academy, in houston, texas * alpha sigma alpha, u.s. national sorority * american society for aesthetics * american student assistance * american studies association * arizona school for the arts * armenian sisters academy * association of social anthropologists * astronomical society of australia * austrian studies association DOCS doc1: alandica shipping academy: maritime education at land our educations include basic courses and refresher courses for seafarers as well as undergraduate educations at high school and college level. stcw-courses about our stcw- courses book your course (in swedish) contact us for help in english hem / alandica shipping academy doc2: en alandica shipping academy sjöfartsutbildningar p land vi erbjuder kurser för sjöfarare, företag och privatpersoner samt grundutbildningar p gymnasie- och högskoleniv. kursverksamhet kurser för sjöfarare stcw kurser för företag, rederier och privatpersoner övrig specialutbildning för sjöfarare varm rökdykning för fbk doc3: alandica shipping academy (also asa) offers maritime education in land, finland and began operations in 2020. asa offers basic courses and refresher courses for seafarers as well as undergraduate education at high school and college level.\n",
      "\n",
      "Tgt query:\n",
      " comment: /* education */ added alandica shipping academy TEXT * african studies association of the united kingdom * african studies association *alandica shipping academy, land islands, finland * albany students' association, at massey university, auckland, new zealand * alexander-smith academy, in houston, texas * alpha sigma alpha, u.s. national sorority * american society for aesthetics * american student assistance * american studies association * arizona school for the arts * armenian sisters academy * association of social anthropologists * astronomical society of australia * austrian studies association\n",
      "\n",
      "\n",
      "----------------------------\t GENERATED\t ----------------------------\n",
      "\n",
      "0:\n",
      "comment: /* education */ added alandica shipping academy TEXT * african studies association of the united kingdom * african studies association *alandica shipping academy, land, finland * albany students' association, at massey university, auckland, new zealand * alexander-smith academy, in houston, texas * alpha sigma alpha, u.s. national sorority * american society for aesthetics * american student assistance * american studies association * arizona school for the arts * armenian sisters academy * association of social anthropologists * astronomical society of australia * austrian studies association\n",
      "\n",
      "1:\n",
      "comment: /* education */ added alandica shipping academy TEXT * african studies association of the united kingdom * african studies association *alandica shipping academy, land, finland * albany students' association, at massey university, auckland, new zealand * alexander-smith academy, in houston, texas * alpha sigma alpha, u.s. national sorority * american society for aesthetics * american student assistance * american studies association * arizona school for the arts * armenian sisters academy * association of social anthropologists * astronomical society of australia * austrian studies association\n",
      "\n",
      "2:\n",
      "comment: /* education */ + alandica shipping academy TEXT * african studies association of the united kingdom * african studies association *alandica shipping academy, land, finland * albany students' association, at massey university, auckland, new zealand * alexander-smith academy, in houston, texas * alpha sigma alpha, u.s. national sorority * american society for aesthetics * american student assistance * american studies association * arizona school for the arts * armenian sisters academy * association of social anthropologists * astronomical society of australia * austrian studies association\n",
      "\n",
      "3:\n",
      "comment: /* education */ add alandica shipping academy TEXT * african studies association of the united kingdom * african studies association *alandica shipping academy, land, finland * albany students' association, at massey university, auckland, new zealand * alexander-smith academy, in houston, texas * alpha sigma alpha, u.s. national sorority * american society for aesthetics * american student assistance * american studies association * arizona school for the arts * armenian sisters academy * association of social anthropologists * astronomical society of australia * austrian studies association\n",
      "\n",
      "4:\n",
      "comment: /* education */ added alandica shipping academy TEXT * african studies association of the united kingdom * african studies association *alandica shipping academy, land, finland * albany students' association, at massey university, auckland, new zealand * alexander-smith academy, in houston, texas * alpha sigma alpha, u.s. national sorority * american society for aesthetics * american student assistance * american studies association * arizona school for the arts * armenian sisters academy * association of social anthropologists * astronomical society of australia * austrian studies association * alandica shipping academy\n",
      "\n",
      "\n",
      "X_T:\n",
      "* African Studies Association of the United Kingdom\n",
      "* African Studies Association\n",
      "* Albany Students' Association, at Massey University, Auckland, New Zealand\n",
      "* Alexander-Smith Academy, in Houston, Texas\n",
      "* Alpha Sigma Alpha, U.S. national sorority\n",
      "* American Society for Aesthetics\n",
      "* American Student Assistance\n",
      "* American Studies Association\n",
      "* Arizona School for the Arts\n",
      "* Armenian Sisters Academy\n",
      "* Association of Social Anthropologists\n",
      "* Astronomical Society of Australia\n",
      "* Austrian Studies Association\n",
      "\n",
      "X_T+1:\n",
      "* African Studies Association of the United Kingdom\n",
      "* African Studies Association\n",
      "*Alandica Shipping Academy, Åland Islands, Finland\n",
      "* Albany Students' Association, at Massey University, Auckland, New Zealand\n",
      "* Alexander-Smith Academy, in Houston, Texas\n",
      "* Alpha Sigma Alpha, U.S. national sorority\n",
      "* American Society for Aesthetics\n",
      "* American Student Assistance\n",
      "* American Studies Association\n",
      "* Arizona School for the Arts\n",
      "* Armenian Sisters Academy\n",
      "* Association of Social Anthropologists\n",
      "* Astronomical Society of Australia\n",
      "* Austrian Studies Association\n",
      "\n",
      "diff:\n",
      "Alandica Shipping Academy, Åland Islands, Finland\n",
      "*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "----------------------------\t QUERY 4\t ----------------------------\n",
      "\n",
      "Src query:\n",
      " TEXT * online and downloadable bambara-french dictionary (about 11,500 entries by the end of 2014), with a french-bambara index, linked with the corpus bambara de référence *bambara entries (>2300) in the french wiktionary *bambara-french-english dictionary online and downloadable lexicons for language learners *bambara tree names (scientific name -> common name) DOCS doc1: $20.87 5 new from $20.87 this book is intended to assist french and english speakers who are visiting west african countries where french and bambara, are spoken. bambara is a mande language used in mali, burkina faso and côte divoire, senegal, gambia, guinea, sierra leone and ghana. doc2: the manding (bambara/jula) dictionary at an ka taa launched in 2019 appears to be the most comprehensive online english-bambara dictionary. it is the mastermind of coleman donaldson, a linguist and manding enthusiast who also produces wonderful videos featuring man on the street interviews with bamakois on a variety of topics. not to be missed. doc3: bambara dictionary - 5000 words online pdf download online bambara dictionary this bambara dictionary contains the 5000 most used words in bambara which are essential for day to day communication. along with the meaning of the word, the dictionary will also provide usage examples. so house o so this house so the house o so ka belebele\n",
      "\n",
      "Tgt query:\n",
      " comment: /* dictionaries */ added an additional bambara-english dictionary that includes a mobile version TEXT * online and downloadable bambara-french dictionary (about 11,500 entries by the end of 2014), with a french-bambara index, linked with the corpus bambara de référence *mobile friendly bambara-english dictionary. additionally includes french and jula. *bambara entries (>2300) in the french wiktionary *bambara-french-english dictionary online and downloadable lexicons for language learners *bambara tree names (scientific name -> common name)\n",
      "\n",
      "\n",
      "----------------------------\t GENERATED\t ----------------------------\n",
      "\n",
      "0:\n",
      "comment: /* dictionaries */ added an additional bambara-english dictionary. TEXT * online and downloadable bambara-french dictionary (about 11,500 entries by the end of 2014), with a french-bambara index, linked with the corpus bambara de référence *bambara entries (>2300) in the french wiktionary *bambara-french-english dictionary online and downloadable lexicons for language learners *bambara tree names (scientific name -> common name) *bambara-english dictionary online and downloadable lexicons for language learners *bambara tree names (scientific name -> common name)\n",
      "\n",
      "1:\n",
      "comment: /* dictionaries */ [[bambara-french dictionary]] TEXT * online and downloadable bambara-french dictionary (about 11,500 entries by the end of 2014), with a french-bambara index, linked with the corpus bambara de référence *bambara entries (>2300) in the french wiktionary *bambara-french-english dictionary online and downloadable lexicons for language learners *bambara tree names (scientific name -> common name) *bambara-english dictionary online and downloadable lexicons for language learners *bambara tree names (scientific name -> common name)\n",
      "\n",
      "2:\n",
      "comment: /* dictionaries */ added an additional bambara-english dictionary that includes a mobile version TEXT * online and downloadable bambara-french dictionary (about 11,500 entries by the end of 2014), with a french-bambara index, linked with the corpus bambara de référence *bambara entries (>2300) in the french wiktionary *bambara-french-english dictionary online and downloadable lexicons for language learners *bambara tree names (scientific name -> common name) *bambara-english dictionary online and downloadable lexicons for language learners *bambara tree names (scientific name -> common name)\n",
      "\n",
      "3:\n",
      "comment: /* dictionaries */ added an additional bambara-english dictionary. TEXT * online and downloadable bambara-french dictionary (about 11,500 entries by the end of 2014), with a french-bambara index, linked with the corpus bambara de référence *bambara entries (>2300) in the french wiktionary *bambara-french-english dictionary online and downloadable lexicons for language learners *bambara tree names (scientific name -> common name) *bambara-english dictionary online and downloadable lexicons for language learners *bambara tree names (scientific name -> common name) *bambara-english dictionary\n",
      "\n",
      "4:\n",
      "comment: /* dictionaries */ [[bambara-french dictionary]] TEXT * online and downloadable bambara-french dictionary (about 11,500 entries by the end of 2014), with a french-bambara index, linked with the corpus bambara de référence *bambara entries (>2300) in the french wiktionary *bambara-french-english dictionary online and downloadable lexicons for language learners *bambara tree names (scientific name -> common name) *bambara tree names (scientific name -> common name)\n",
      "\n",
      "\n",
      "X_T:\n",
      "* online and downloadable Bambara-French Dictionary (about 11,500 entries by the end of 2014), with a French-Bambara index, linked with the Corpus Bambara de Référence\n",
      "*Bambara entries (>2300) in the French Wiktionary\n",
      "*Bambara-French-English dictionary online and downloadable lexicons for language learners\n",
      "*Bambara tree names (scientific name -> common name)\n",
      "\n",
      "X_T+1:\n",
      "* online and downloadable Bambara-French Dictionary (about 11,500 entries by the end of 2014), with a French-Bambara index, linked with the Corpus Bambara de Référence\n",
      "*Mobile friendly Bambara-English dictionary. Additionally includes French and Jula.\n",
      "*Bambara entries (>2300) in the French Wiktionary\n",
      "*Bambara-French-English dictionary online and downloadable lexicons for language learners\n",
      "*Bambara tree names (scientific name -> common name)\n",
      "\n",
      "diff:\n",
      "Mobile friendly Bambara-English dictionary. Additionally includes French and Jula.\n",
      "*Bambara entries\n"
     ]
    }
   ],
   "source": [
    "device = runner.engine.device\n",
    "runner.model.eval()\n",
    "with torch.no_grad():\n",
    "    for i in [0, 1, 2, 3, 4]:\n",
    "        src_, tgt_ = ds_edit[i]\n",
    "        src_inp = torch.tensor(src_['input_ids']).view(1,-1).to(runner.engine.device)\n",
    "        generated = runner.model.pretrained.generate(src_inp,\n",
    "                                              attention_mask=(src_inp != 0).float().to(runner.engine.device),\n",
    "                                            # pad_token_id=tokenizer.pad_token_id,\n",
    "                                            # bos_token_id=tokenizer.bos_token_id,\n",
    "                                            # eos_token_id=tokenizer.eos_token_id,\n",
    "                                              num_beams=CONFIG.beam_size,\n",
    "                                              num_return_sequences=CONFIG.beam_size,\n",
    "                                              max_length=1000\n",
    "        )\n",
    "        src_text = tokenizer.decode(src_['input_ids'], skip_special_tokens=True)\n",
    "        tgt_text = tokenizer.decode(tgt_['input_ids'], skip_special_tokens=True)\n",
    "        print(f'\\n\\n----------------------------\\t QUERY {i}\\t ----------------------------\\n')\n",
    "        print(f'Src query:\\n {src_text}')\n",
    "        print(f'\\nTgt query:\\n {tgt_text}')\n",
    "        \n",
    "        print(f'\\n\\n----------------------------\\t GENERATED\\t ----------------------------\\n')\n",
    "\n",
    "        for j in range(CONFIG.beam_size):\n",
    "            to_gen = generated[j]\n",
    "            gen_text = tokenizer.decode(to_gen, skip_special_tokens=True)\n",
    "            print(f'{j}:\\n{gen_text}\\n')\n",
    "        \n",
    "        src_text = df.iloc[i]['old_text']\n",
    "        tgt_text = df.iloc[i]['new_text']\n",
    "        diff_text = df.iloc[i]['diff']\n",
    "        print(f'\\nX_T:\\n{src_text}')\n",
    "        print(f'\\nX_T+1:\\n{tgt_text}')\n",
    "        print(f'\\ndiff:\\n{diff_text}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import difflib\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from difflib import Differ \n",
    "from wiki_data_old.utils.difflibparser import DifflibParser, DiffCode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_diff_num2(prev_sections_texts, new_sections_texts):\n",
    "    differ_obj = Differ()\n",
    "    dif_result = list(DifflibParser(prev_sections_texts, new_sections_texts))\n",
    "    result = []\n",
    "    result_idxs = []\n",
    "    old_text, new_text, last_diff_id = [], [], -1000\n",
    "    for dif_id, dif_line in enumerate(dif_result):\n",
    "        if np.abs(dif_id - last_diff_id) > 0:\n",
    "            nl_ = ''\n",
    "            ol_ = dif_line['line']\n",
    "            code = dif_line['code']\n",
    "            if 'newline' in dif_line:\n",
    "                nl_ = dif_line['newline']\n",
    "            dif_line_str = f'{ol_}_{nl_}_{code}'\n",
    "            result.append(dif_line_str)\n",
    "            result_idxs.append(dif_id)\n",
    "            last_diff_id = dif_id\n",
    "    return set(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f0d2358f50645778559bd53e7eaafa6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=103.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "em1, em5, dm1, dm5, total = 0, 0, 0, 0, 0\n",
    "\n",
    "for i in tqdm(range(len(ds_val)), total=len(ds_val), position=0, leave=True):\n",
    "    src_, tgt_ = ds_edit[i]\n",
    "    src_inp = torch.tensor(src_['input_ids']).view(1,-1).to(runner.engine.device)\n",
    "    generated = runner.model.pretrained.generate(src_inp,\n",
    "                                              attention_mask=(src_inp != 0).float().to(runner.engine.device),\n",
    "                                            # pad_token_id=tokenizer.pad_token_id,\n",
    "                                            # bos_token_id=tokenizer.bos_token_id,\n",
    "                                            # eos_token_id=tokenizer.eos_token_id,\n",
    "                                              num_beams=CONFIG.beam_size,\n",
    "                                              num_return_sequences=CONFIG.beam_size,\n",
    "                                              max_length=1000\n",
    "        )\n",
    "        \n",
    "    src_text = tokenizer.decode(src_['input_ids'], skip_special_tokens=True).split('TEXT')[1].split('DOCS')[0].strip()\n",
    "    tgt_text = tokenizer.decode(tgt_['input_ids'], skip_special_tokens=True).split('TEXT')[1].strip()\n",
    "    \n",
    "    gen_texts = []\n",
    "    for j in range(CONFIG.beam_size):\n",
    "        to_gen = generated[j]\n",
    "        gen_text = tokenizer.decode(to_gen, skip_special_tokens=True)\n",
    "        if 'TEXT' in gen_text:\n",
    "            gen_text = gen_text.split('TEXT')[1].strip()\n",
    "        gen_texts.append(gen_text)\n",
    "    \n",
    "    \n",
    "    src_sents = sent_tokenize(src_text)\n",
    "    tgt_sents = sent_tokenize(tgt_text)\n",
    "    gen_sents = [sent_tokenize(a) for a in gen_texts]\n",
    "    \n",
    "    tdiff = get_diff_num2(src_sents, tgt_sents)\n",
    "    gen_diffs = [get_diff_num2(src_sents, b) for b in gen_sents]\n",
    "    \n",
    "    if len(tdiff) == 0:\n",
    "        continue\n",
    "    \n",
    "    marks = [(len(tdiff.intersection(b)) / max(len(tdiff), len(b))) for b in gen_diffs]\n",
    "    \n",
    "    if tgt_text == gen_texts[0]:\n",
    "        em1 += 1\n",
    "    if tgt_text in gen_texts:\n",
    "        em5 += 1\n",
    "        \n",
    "    dm1 += marks[0]\n",
    "    dm5 += max(marks)\n",
    "    total += 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17, 28, 55.88492063492061, 60.71944444444441, 103)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "em1, em5, dm1, dm5, total "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.1650485436893204,\n",
       " 0.27184466019417475,\n",
       " 0.5425720449992293,\n",
       " 0.589509169363538)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "em1 / total, em5 / total, dm1 / total, dm5 / total "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
