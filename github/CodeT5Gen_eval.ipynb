{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d5c54e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "83a4e8c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TOKENIZERS_PARALLELISM']='true'\n",
    "os.environ['CUDA_VISIBLE_DEVICES']='2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "73de4b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import torch\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import transformers\n",
    "import catalyst\n",
    "import difflib\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from transformers import T5Tokenizer, T5TokenizerFast, T5ForConditionalGeneration\n",
    "from transformers.tokenization_utils import PreTrainedTokenizer\n",
    "from transformers.tokenization_utils_fast import PreTrainedTokenizerFast\n",
    "from typing import Callable, Union, Tuple\n",
    "from catalyst.loggers.wandb import WandbLogger\n",
    "from tqdm.notebook import tqdm\n",
    "from collections import Counter\n",
    "from torch import nn\n",
    "from catalyst import dl\n",
    "from catalyst.callbacks.periodic_loader import PeriodicLoaderCallback\n",
    "from langdetect import detect\n",
    "from easse.sari import corpus_sari\n",
    "from rouge import Rouge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "99495a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class Config:\n",
    "    pass\n",
    "\n",
    "CONFIG = Config()\n",
    "CONFIG.seed = 1337\n",
    "\n",
    "import random\n",
    "\n",
    "random.seed(CONFIG.seed)\n",
    "os.environ['PYTHONHASHSEED'] = str(CONFIG.seed)\n",
    "np.random.seed(CONFIG.seed)\n",
    "torch.manual_seed(CONFIG.seed)\n",
    "torch.cuda.manual_seed(CONFIG.seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c56b00cf",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3f5804dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import CodeGenForCausalLM, AutoTokenizer\n",
    "from transformers import RobertaTokenizer, T5ForConditionalGeneration\n",
    "\n",
    "CONFIG.src_max_len = 512\n",
    "CONFIG.tgt_max_len = 512\n",
    "CONFIG.pretrained = 'Salesforce/codet5-small'\n",
    "\n",
    "tokenizer = RobertaTokenizer.from_pretrained(CONFIG.pretrained)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = T5ForConditionalGeneration.from_pretrained(CONFIG.pretrained).to(device)\n",
    "\n",
    "SEP_TOKEN = str(tokenizer.__dict__['init_kwargs']['sep_token'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b15814f3",
   "metadata": {},
   "source": [
    "## Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "645b05d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(74455, 10)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_new_disk = pd.read_json(r'data/final_data.json')\n",
    "df_new_disk.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8b24771d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>code_before</th>\n",
       "      <th>code_after</th>\n",
       "      <th>commit_msg</th>\n",
       "      <th>com_py2imports_before</th>\n",
       "      <th>com_py2imports_after</th>\n",
       "      <th>diff</th>\n",
       "      <th>com_hash</th>\n",
       "      <th>imports</th>\n",
       "      <th>lib8funcs</th>\n",
       "      <th>docs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>def _misc(self, func, opts, args):\\n      ...</td>\n",
       "      <td>def _misc(self, func, opts, args):\\n      ...</td>\n",
       "      <td>http://code.google.com/p/pytyrant/issues/detai...</td>\n",
       "      <td>{'0_pytyrant.py': ['import socket', 'import st...</td>\n",
       "      <td>{'0_pytyrant.py': ['import socket', 'import st...</td>\n",
       "      <td>@@ -493,8 +493,10 @@ class Tyrant(object):\\n  ...</td>\n",
       "      <td>32618ec0a7a05bad587064e20adfb80cb7bd1860</td>\n",
       "      <td>[import UserDict, import struct, import socket]</td>\n",
       "      <td>[{'UserDict': '*', 'struct': '*', 'socket': '*...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>def _tDouble(code, key, integ, fract):\\n    re...</td>\n",
       "      <td>def _tDouble(code, key, integ, fract):\\n    re...</td>\n",
       "      <td>fix adddouble typo</td>\n",
       "      <td>{'0_pytyrant.py': ['import math', 'import sock...</td>\n",
       "      <td>{'0_pytyrant.py': ['import math', 'import sock...</td>\n",
       "      <td>@@ -147,7 +147,7 @@ def _t3F(code, func, opts,...</td>\n",
       "      <td>8b5d9f765a0fbbd76cc7b7ff8d2593436c6a2360</td>\n",
       "      <td>[import struct, import UserDict, import math, ...</td>\n",
       "      <td>[{'struct': '*', 'UserDict': '*', 'math': '*',...</td>\n",
       "      <td>[Functions to convert between Python values an...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         code_before  \\\n",
       "0      def _misc(self, func, opts, args):\\n      ...   \n",
       "1  def _tDouble(code, key, integ, fract):\\n    re...   \n",
       "\n",
       "                                          code_after  \\\n",
       "0      def _misc(self, func, opts, args):\\n      ...   \n",
       "1  def _tDouble(code, key, integ, fract):\\n    re...   \n",
       "\n",
       "                                          commit_msg  \\\n",
       "0  http://code.google.com/p/pytyrant/issues/detai...   \n",
       "1                                 fix adddouble typo   \n",
       "\n",
       "                               com_py2imports_before  \\\n",
       "0  {'0_pytyrant.py': ['import socket', 'import st...   \n",
       "1  {'0_pytyrant.py': ['import math', 'import sock...   \n",
       "\n",
       "                                com_py2imports_after  \\\n",
       "0  {'0_pytyrant.py': ['import socket', 'import st...   \n",
       "1  {'0_pytyrant.py': ['import math', 'import sock...   \n",
       "\n",
       "                                                diff  \\\n",
       "0  @@ -493,8 +493,10 @@ class Tyrant(object):\\n  ...   \n",
       "1  @@ -147,7 +147,7 @@ def _t3F(code, func, opts,...   \n",
       "\n",
       "                                   com_hash  \\\n",
       "0  32618ec0a7a05bad587064e20adfb80cb7bd1860   \n",
       "1  8b5d9f765a0fbbd76cc7b7ff8d2593436c6a2360   \n",
       "\n",
       "                                             imports  \\\n",
       "0    [import UserDict, import struct, import socket]   \n",
       "1  [import struct, import UserDict, import math, ...   \n",
       "\n",
       "                                           lib8funcs  \\\n",
       "0  [{'UserDict': '*', 'struct': '*', 'socket': '*...   \n",
       "1  [{'struct': '*', 'UserDict': '*', 'math': '*',...   \n",
       "\n",
       "                                                docs  \n",
       "0                                                 []  \n",
       "1  [Functions to convert between Python values an...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new_disk.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "396c523f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new_disk['file_name'] = df_new_disk['com_py2imports_after'].apply(lambda x: list(x)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "51bac252",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_prompts(row):\n",
    "    fn = row['file_name']\n",
    "    code_before = row['code_before']\n",
    "    commit_msg = row['commit_msg']\n",
    "    return f'{commit_msg} {SEP_TOKEN} {code_before}\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "14e2497f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new_disk['prompt'] = df_new_disk.apply(lambda x: generate_prompts(x), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5d5b6730",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fix RBF features. </s>     def __init__(self, nrows = 5, ncols = 5, walls=[(1,1),(1,2),(1,3),(2,1),(2,2),(2,3),(3,1),(3,2),(3,3)], endstates = [0]):\n",
      "        self.nrows = nrows\n",
      "        self.ncols = ncols\n",
      "\n",
      "        self.walls = walls\n",
      "        grid = [self.coords(i) for i in range(self.nrows * self.ncols)]\n",
      "        grid = [s for s in grid if not s in self.walls]\n",
      "        self.states = dict([(i,s) for (i,s) in enumerate(grid)])\n",
      "        self.rstates = dict([(s,i) for (i,s) in enumerate(grid)]) # reverse lookup by grid coords\n",
      "\n",
      "        self.nstates = len(self.states)\n",
      "        self.nactions = 8\n",
      "        self.endstates = endstates\n",
      "\n",
      "        MDP.__init__(self, nstates = self.nstates, nactions = self.nactions)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(df_new_disk['prompt'].iloc[100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1a18745c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/test_idxs.npy', 'rb') as f:\n",
    "    X_test_idx = np.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "67a46a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = df_new_disk.iloc[X_test_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "56433f90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7446, 12)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f46059fe",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c8b2ce9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Union, Callable, Tuple\n",
    "from transformers.tokenization_utils import PreTrainedTokenizer\n",
    "from transformers.tokenization_utils_fast import PreTrainedTokenizerFast\n",
    "\n",
    "class EditDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, \n",
    "                 dataset: pd.DataFrame, \n",
    "                 tokenizer: Union[PreTrainedTokenizer, PreTrainedTokenizerFast],\n",
    "                 config):\n",
    "        self.db = dataset\n",
    "        self.tokenizer = tokenizer\n",
    "        \n",
    "        src_text = self.db['prompt'].values\n",
    "        tgt_text = self.db['code_after'].values\n",
    "        \n",
    "        self.src_text_tokenized = [tokenizer(x,\n",
    "                                       max_length=config.src_max_len,\n",
    "                                       truncation=True,\n",
    "                                       return_attention_mask=False,\n",
    "                                       ) for x in src_text]\n",
    "        self.tgt_text_tokenized = [tokenizer(x,\n",
    "                                       max_length=config.tgt_max_len,\n",
    "                                       truncation=True,\n",
    "                                       return_attention_mask=False,\n",
    "                                       ) for x in tgt_text]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.db)\n",
    "\n",
    "    def __getitem__(self, \n",
    "                    idx: int) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "        src = self.src_text_tokenized[idx]\n",
    "        tgt = self.tgt_text_tokenized[idx]\n",
    "        return src, tgt\n",
    "    \n",
    "    @staticmethod\n",
    "    def collate_fn_new(samples: Tuple[torch.Tensor, torch.Tensor], \n",
    "                   tokenizer: Union[PreTrainedTokenizer, PreTrainedTokenizerFast], \n",
    "                   config: Config) -> Tuple[Tuple[torch.Tensor, torch.Tensor], torch.Tensor]:\n",
    "        src_samples = [x[0] for x in samples]\n",
    "        tgt_samples = [x[1] for x in samples]\n",
    "\n",
    "        src_samples = tokenizer.pad(src_samples,\n",
    "                                    padding='longest',\n",
    "                                    max_length=config.src_max_len,\n",
    "                                    return_attention_mask=False,\n",
    "                                    return_tensors='pt')['input_ids']\n",
    "\n",
    "        tgt_samples = tokenizer.pad(tgt_samples,\n",
    "                                    padding='longest',\n",
    "                                    max_length=config.tgt_max_len,\n",
    "                                    return_attention_mask=False,\n",
    "                                    return_tensors='pt')['input_ids']\n",
    "\n",
    "        return (src_samples, tgt_samples), tgt_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f84e9a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ds = EditDataset(X_test, tokenizer, CONFIG)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2db868ea",
   "metadata": {},
   "source": [
    "## Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "852e35d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG.batch_size = 16\n",
    "loaders = {\n",
    "    'valid_full': torch.utils.data.DataLoader(test_ds, \n",
    "                                         batch_size=CONFIG.batch_size,\n",
    "                                         collate_fn=lambda x: EditDataset.collate_fn_new(x, tokenizer, CONFIG),\n",
    "                                         num_workers=4, shuffle=False)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9c9e6608",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EditModel(nn.Module):\n",
    "    def __init__(self, \n",
    "                 pretrained: transformers.modeling_utils.PreTrainedModel, \n",
    "                 config: Config):\n",
    "        super(EditModel, self).__init__()\n",
    "        self.pretrained = pretrained\n",
    "        \n",
    "\n",
    "    def forward(self, \n",
    "                x: Tuple[torch.Tensor, torch.Tensor]):\n",
    "        src, tgt = x\n",
    "        \n",
    "        tgt[tgt == 0] == -100\n",
    "        \n",
    "        loss = self.pretrained(\n",
    "            input_ids = src,\n",
    "            attention_mask = (src != 0).float(),\n",
    "            labels=tgt,\n",
    "        ).loss\n",
    "        return loss\n",
    "    \n",
    "    \n",
    "class Criterion(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Criterion, self).__init__()\n",
    "        \n",
    "    def forward(self, pred, tgt):\n",
    "        return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "36d2c28e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'codet5-small p(x_t+1 | x_t, commit_msg)'\r\n"
     ]
    }
   ],
   "source": [
    "!ls ./models/Salesforce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f06f1552",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success\n"
     ]
    }
   ],
   "source": [
    "CONFIG.pattern_path = './models/Salesforce/codet5-small p(x_t+1 | x_t, commit_msg)'\n",
    "CONFIG.device = 'cuda'\n",
    "\n",
    "model_edit = EditModel(T5ForConditionalGeneration.from_pretrained(CONFIG.pretrained), CONFIG)\n",
    "model_edit.load_state_dict(\n",
    "    torch.load(f'{CONFIG.pattern_path}/checkpoints/model.best.pth', \n",
    "               map_location=CONFIG.device))\n",
    "model_edit = model_edit.pretrained\n",
    "model_edit.to(CONFIG.device)\n",
    "model_edit.eval()\n",
    "print('Success')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "45c5702e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e413b8bed0240639f0a5c226ee843ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/466 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "device = CONFIG.device\n",
    "CONFIG.beam_size = 1\n",
    "\n",
    "predictions = []\n",
    "with torch.no_grad():\n",
    "    for batch_idx, batch in tqdm(enumerate(loaders['valid_full']), total=len(loaders['valid_full'])):\n",
    "        (src_, tgt_), _ = batch\n",
    "        \n",
    "        generated = model_edit.generate(src_.to(device), \n",
    "                                        num_beams=CONFIG.beam_size,\n",
    "                                        num_return_sequences=1,\n",
    "                                        max_length=512)\n",
    "        generated = generated.cpu()\n",
    "        \n",
    "        pred = generated.view(-1, CONFIG.beam_size, generated.shape[1])\n",
    "        for i in range(pred.shape[0]):\n",
    "            pred_full = []\n",
    "            for pred_item in pred[i]:\n",
    "                txt_pred = tokenizer.decode(pred_item, skip_special_tokens=True)\n",
    "                pred_full.append(txt_pred)\n",
    "            predictions.append(pred_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "db612238",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    def on_mode(self, c, e):\n",
      "        self.write_event(\"mode\", e,\n",
      "                         {\"%modes%\" : e.arguments()[0],\n",
      "                          \"%person%\" : e.arguments()[1],\n",
      "                          \"%giver%\" : nm_to_n(e.source()),\n",
      "                         })\n"
     ]
    }
   ],
   "source": [
    "print(predictions[5][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "60568512",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    def on_mode(self, c, e):\n",
      "        self.write_event(\"mode\", e,\n",
      "                         {\"%modes%\" : e.arguments()[0],\n",
      "                          \"%person%\" : e.arguments()[1] if len(e.arguments()) > 1 else \"\",\n",
      "                          \"%giver%\" : nm_to_n(e.source()),\n",
      "                         })\n"
     ]
    }
   ],
   "source": [
    "print(X_test['code_after'].iloc[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f18aeb42",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test['predicted_text'] = [el[0] for el in predictions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8e27fc82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1073\n",
      "0.14410421702927748\n"
     ]
    }
   ],
   "source": [
    "print(np.sum(X_test['predicted_text'] == X_test['code_after']))\n",
    "print(np.sum(X_test['predicted_text'] == X_test['code_after']) / X_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "36b5b72f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "499\n",
      "0.06701584743486436\n"
     ]
    }
   ],
   "source": [
    "print(np.sum(X_test['code_before'] == X_test['code_after']))\n",
    "print(np.sum(X_test['code_before'] == X_test['code_after']) / X_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1b67a23",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d5fa0b6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
